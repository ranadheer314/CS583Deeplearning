{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"Class\",\"Alcohol\",\"Malic_acid\",\"Ash\",\"Alcalinity_ash\",\"Magnesium\",\"Total_phenols\",\"Flavanoids\",\"Nonflavanoid_phenols\",\"Proanthocyanins\" ,\"Color_intensity\",\"Hue\",\"OD280/OD315 of diluted wines\",\"Proline\"]\n",
    "data=pd.read_csv(\"wine.csv\",names=cols) #loading data\n",
    "X=data.iloc[:,1:]\n",
    "Y=data[\"Class\"]-1 # changed wine classes from 1,2,3 to 0,1,2\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=12) # splitting the dataset into test and train\n",
    "#standarization of features\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "8/8 [==============================] - 0s 872us/step - loss: 1.2691 - accuracy: 0.1613\n",
      "Epoch 2/35\n",
      "8/8 [==============================] - 0s 750us/step - loss: 1.2062 - accuracy: 0.2661\n",
      "Epoch 3/35\n",
      "8/8 [==============================] - 0s 875us/step - loss: 1.1581 - accuracy: 0.3145\n",
      "Epoch 4/35\n",
      "8/8 [==============================] - 0s 877us/step - loss: 1.1174 - accuracy: 0.3548\n",
      "Epoch 5/35\n",
      "8/8 [==============================] - 0s 875us/step - loss: 1.0861 - accuracy: 0.4516\n",
      "Epoch 6/35\n",
      "8/8 [==============================] - 0s 750us/step - loss: 1.0567 - accuracy: 0.5000\n",
      "Epoch 7/35\n",
      "8/8 [==============================] - 0s 875us/step - loss: 1.0306 - accuracy: 0.5484\n",
      "Epoch 8/35\n",
      "8/8 [==============================] - 0s 875us/step - loss: 1.0020 - accuracy: 0.5484\n",
      "Epoch 9/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.9729 - accuracy: 0.6048\n",
      "Epoch 10/35\n",
      "8/8 [==============================] - 0s 500us/step - loss: 0.9436 - accuracy: 0.6452\n",
      "Epoch 11/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.9107 - accuracy: 0.6935\n",
      "Epoch 12/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.8717 - accuracy: 0.7581\n",
      "Epoch 13/35\n",
      "8/8 [==============================] - 0s 500us/step - loss: 0.8301 - accuracy: 0.7903\n",
      "Epoch 14/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.7778 - accuracy: 0.8306\n",
      "Epoch 15/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.7256 - accuracy: 0.8871\n",
      "Epoch 16/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.6647 - accuracy: 0.9194\n",
      "Epoch 17/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.6029 - accuracy: 0.9355\n",
      "Epoch 18/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.5388 - accuracy: 0.9274\n",
      "Epoch 19/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.4758 - accuracy: 0.9355\n",
      "Epoch 20/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.4154 - accuracy: 0.9435\n",
      "Epoch 21/35\n",
      "8/8 [==============================] - 0s 627us/step - loss: 0.3618 - accuracy: 0.9516\n",
      "Epoch 22/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.3165 - accuracy: 0.9516\n",
      "Epoch 23/35\n",
      "8/8 [==============================] - 0s 500us/step - loss: 0.2770 - accuracy: 0.9516\n",
      "Epoch 24/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.2447 - accuracy: 0.9516\n",
      "Epoch 25/35\n",
      "8/8 [==============================] - 0s 624us/step - loss: 0.2167 - accuracy: 0.9516\n",
      "Epoch 26/35\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.1937 - accuracy: 0.9597\n",
      "Epoch 27/35\n",
      "8/8 [==============================] - 0s 500us/step - loss: 0.1744 - accuracy: 0.9677\n",
      "Epoch 28/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.1582 - accuracy: 0.9677\n",
      "Epoch 29/35\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.1439 - accuracy: 0.9677\n",
      "Epoch 30/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.1314 - accuracy: 0.9677\n",
      "Epoch 31/35\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.1196 - accuracy: 0.9677\n",
      "Epoch 32/35\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.1103 - accuracy: 0.9758\n",
      "Epoch 33/35\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.1017 - accuracy: 0.9758\n",
      "Epoch 34/35\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.0946 - accuracy: 0.9758\n",
      "Epoch 35/35\n",
      "8/8 [==============================] - 0s 627us/step - loss: 0.0874 - accuracy: 0.9839\n",
      "4/4 [==============================] - 0s 498us/step - loss: 0.0603 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06025603413581848, 1.0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                         tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(3,activation=tf.nn.softmax)])\n",
    "model.compile(optimizer=tf.optimizers.Adam(),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs=35,batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 752us/step - loss: 0.0603 - accuracy: 1.0000\n",
      "[0.06025603413581848, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test,Y_test,batch_size=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accuracy of this neural network on test dataset is 100%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 1.1414 - accuracy: 0.4032\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 830us/step - loss: 1.1163 - accuracy: 0.4032\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 1.0947 - accuracy: 0.4113\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.0720 - accuracy: 0.4274\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.0534 - accuracy: 0.4355\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 1.0374 - accuracy: 0.4839\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.0216 - accuracy: 0.4919\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 1.0069 - accuracy: 0.5000\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9920 - accuracy: 0.5081\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.9772 - accuracy: 0.5403\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.9623 - accuracy: 0.5726\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.9473 - accuracy: 0.5968\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.9332 - accuracy: 0.6129\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.9173 - accuracy: 0.6290\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.9027 - accuracy: 0.6371\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.8873 - accuracy: 0.6532\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.8721 - accuracy: 0.6694\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 0.8564 - accuracy: 0.6694\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.8407 - accuracy: 0.7016\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.8241 - accuracy: 0.7339\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.8074 - accuracy: 0.7500\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.7910 - accuracy: 0.7742\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.7732 - accuracy: 0.7823\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7556 - accuracy: 0.7984\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.7374 - accuracy: 0.8065\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7184 - accuracy: 0.8145\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7005 - accuracy: 0.8145\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.6817 - accuracy: 0.8226\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.6628 - accuracy: 0.8306\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.6441 - accuracy: 0.8468\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.6253 - accuracy: 0.8629\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.6065 - accuracy: 0.8710\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5868 - accuracy: 0.8710\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5677 - accuracy: 0.9113\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5489 - accuracy: 0.9194\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB033A84C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6429 - accuracy: 0.9524WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.9444\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 835us/step - loss: 0.9218 - accuracy: 0.6210\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.4181 - accuracy: 0.9355\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9516\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 835us/step - loss: 0.0427 - accuracy: 0.9919\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.0309 - accuracy: 0.9919\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 837us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 3.4149e-04 - accuracy: 1.0000\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.2984e-04 - accuracy: 1.0000\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.2736e-04 - accuracy: 1.0000\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.7216e-04 - accuracy: 1.0000\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.0364e-04 - accuracy: 1.0000\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.9924e-04 - accuracy: 1.0000\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.5448e-04 - accuracy: 1.0000\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.1489e-04 - accuracy: 1.0000\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 8.7010e-05 - accuracy: 1.0000\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 7.3418e-05 - accuracy: 1.0000\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 6.6677e-05 - accuracy: 1.0000\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.9491e-05 - accuracy: 1.0000\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.3522e-05 - accuracy: 1.0000\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 5.0700e-05 - accuracy: 1.0000\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 4.7044e-05 - accuracy: 1.0000\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 4.4744e-05 - accuracy: 1.0000\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 4.2295e-05 - accuracy: 1.0000\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.9992e-05 - accuracy: 1.0000\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.8614e-05 - accuracy: 1.0000\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.6973e-05 - accuracy: 1.0000\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.5420e-05 - accuracy: 1.0000\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.3943e-05 - accuracy: 1.0000\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.2714e-05 - accuracy: 1.0000\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.1319e-05 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.0269e-05 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 2.9381e-05 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.8420e-05 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.7316e-05 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.6441e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7D692F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0451 - accuracy: 0.9524WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9630\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.8751 - accuracy: 0.5565\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2455 - accuracy: 0.9435\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.0798 - accuracy: 0.9677\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0365 - accuracy: 0.9919\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 3.7075e-04 - accuracy: 1.0000\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.8281e-04 - accuracy: 1.0000\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.7105e-04 - accuracy: 1.0000\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.0782e-04 - accuracy: 1.0000\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.2710e-04 - accuracy: 1.0000\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 1.0889e-04 - accuracy: 1.0000\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 8.1018e-05 - accuracy: 1.0000\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 6.4461e-05 - accuracy: 1.0000\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.7573e-05 - accuracy: 1.0000\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 4.8201e-05 - accuracy: 1.0000\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 4.0592e-05 - accuracy: 1.0000\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 3.7314e-05 - accuracy: 1.0000\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 501us/step - loss: 3.3457e-05 - accuracy: 1.0000\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 3.0770e-05 - accuracy: 1.0000\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 2.8434e-05 - accuracy: 1.0000\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.6282e-05 - accuracy: 1.0000\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.4156e-05 - accuracy: 1.0000\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.2972e-05 - accuracy: 1.0000\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.1274e-05 - accuracy: 1.0000\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.9949e-05 - accuracy: 1.0000\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.9159e-05 - accuracy: 1.0000\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.8047e-05 - accuracy: 1.0000\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.6762e-05 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.6013e-05 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.5081e-05 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.4557e-05 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.3875e-05 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.3079e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB04C26700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 334us/step - loss: 0.1579 - accuracy: 0.9815\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.4701 - accuracy: 0.8065\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9839\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.1421 - accuracy: 0.9677\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.4624 - accuracy: 0.9758\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0579 - accuracy: 0.9919\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0733 - accuracy: 0.9677\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0324 - accuracy: 0.9919\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0141 - accuracy: 0.9919\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 6.1312e-04 - accuracy: 1.0000\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.1640e-04 - accuracy: 1.0000\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.2805e-04 - accuracy: 1.0000\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.6342e-04 - accuracy: 1.0000\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.4153e-04 - accuracy: 1.0000\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.1875e-04 - accuracy: 1.0000\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0490e-04 - accuracy: 1.0000\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 9.8304e-05 - accuracy: 1.0000\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 9.1550e-05 - accuracy: 1.0000\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 8.3625e-05 - accuracy: 1.0000\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 7.8878e-05 - accuracy: 1.0000\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 7.2653e-05 - accuracy: 1.0000\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 6.8444e-05 - accuracy: 1.0000\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 6.6014e-05 - accuracy: 1.0000\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 6.2499e-05 - accuracy: 1.0000\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 5.8477e-05 - accuracy: 1.0000\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 832us/step - loss: 5.6132e-05 - accuracy: 1.0000\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 5.3058e-05 - accuracy: 1.0000\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.0198e-05 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 4.8215e-05 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 4.5832e-05 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 4.4269e-05 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 4.1938e-05 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 4.0153e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB037170D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.1558 - accuracy: 0.9815\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 924us/step - loss: 0.4835 - accuracy: 0.8306\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.2381 - accuracy: 0.9355\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.0618 - accuracy: 0.9919\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 837us/step - loss: 0.0881 - accuracy: 0.9839\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.1768 - accuracy: 0.9516\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0815 - accuracy: 0.9919\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.0166 - accuracy: 0.9919\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9919\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.0079 - accuracy: 0.9919\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.0226e-04 - accuracy: 1.0000\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.3652e-04 - accuracy: 1.0000\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0894e-04 - accuracy: 1.0000\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 7.3736e-05 - accuracy: 1.0000\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 4.5871e-05 - accuracy: 1.0000\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.9382e-05 - accuracy: 1.0000\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.6807e-05 - accuracy: 1.0000\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 3.4310e-05 - accuracy: 1.0000\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 3.1928e-05 - accuracy: 1.0000\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 3.0423e-05 - accuracy: 1.0000\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.9565e-05 - accuracy: 1.0000\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.7188e-05 - accuracy: 1.0000\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.6308e-05 - accuracy: 1.0000\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 2.5142e-05 - accuracy: 1.0000\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.4299e-05 - accuracy: 1.0000\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 2.3091e-05 - accuracy: 1.0000\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.2054e-05 - accuracy: 1.0000\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 2.1204e-05 - accuracy: 1.0000\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 2.0479e-05 - accuracy: 1.0000\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.9502e-05 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.8858e-05 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.8531e-05 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.7565e-05 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.7096e-05 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.6418e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7C2E60D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 666us/step - loss: 1.0287 - accuracy: 0.9815\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.6205 - accuracy: 0.6613\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.3430 - accuracy: 0.8952\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.2223 - accuracy: 0.9435\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.0228 - accuracy: 0.9919\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.0303 - accuracy: 0.9758\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.1201 - accuracy: 0.9758\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 836us/step - loss: 0.0348 - accuracy: 0.9839\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 2.8093e-04 - accuracy: 1.0000\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 669us/step - loss: 1.4981e-04 - accuracy: 1.0000\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.1185e-05 - accuracy: 1.0000\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 4.9995e-05 - accuracy: 1.0000\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.8418e-05 - accuracy: 1.0000\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.4339e-05 - accuracy: 1.0000\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 5.3188e-06 - accuracy: 1.0000\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.1680e-06 - accuracy: 1.0000\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 4.2173e-06 - accuracy: 1.0000\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.8904e-06 - accuracy: 1.0000\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.6088e-06 - accuracy: 1.0000\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 2.9234e-06 - accuracy: 1.0000\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.9388e-06 - accuracy: 1.0000\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 2.7667e-06 - accuracy: 1.0000\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 2.7177e-06 - accuracy: 1.0000\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.5581e-06 - accuracy: 1.0000\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.4870e-06 - accuracy: 1.0000\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.3783e-06 - accuracy: 1.0000\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 2.4024e-06 - accuracy: 1.0000\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 2.3226e-06 - accuracy: 1.0000\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 2.2659e-06 - accuracy: 1.0000\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 2.1563e-06 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.1140e-06 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 2.0996e-06 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.0246e-06 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.9611e-06 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 1.9246e-06 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB033D7D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1307 - accuracy: 0.9524WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.9630\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.7562 - accuracy: 0.6129\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.9597\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.0976 - accuracy: 0.9758\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.0770 - accuracy: 0.9839\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9919\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.0388 - accuracy: 0.9919\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.0359 - accuracy: 0.9839\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0301 - accuracy: 0.9919\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 835us/step - loss: 0.0329 - accuracy: 0.9919\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 837us/step - loss: 0.0277 - accuracy: 0.9919\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 835us/step - loss: 0.0207 - accuracy: 0.9919\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 835us/step - loss: 0.0307 - accuracy: 0.9839\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0123 - accuracy: 0.9919\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.0112 - accuracy: 0.9919\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0098 - accuracy: 0.9919\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 9.7096e-04 - accuracy: 1.0000\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 7.1033e-04 - accuracy: 1.0000\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 4.9233e-04 - accuracy: 1.0000\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 3.4280e-04 - accuracy: 1.0000\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 2.7643e-04 - accuracy: 1.0000\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.0124e-04 - accuracy: 1.0000\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.7090e-04 - accuracy: 1.0000\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.4446e-04 - accuracy: 1.0000\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.2973e-04 - accuracy: 1.0000\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.1166e-04 - accuracy: 1.0000\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0060e-04 - accuracy: 1.0000\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 9.1431e-05 - accuracy: 1.0000\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 8.5510e-05 - accuracy: 1.0000\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 7.6079e-05 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 7.1269e-05 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 6.9371e-05 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 6.2436e-05 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.9302e-05 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.5048e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB05CA0F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.2478 - accuracy: 0.9815\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.8231 - accuracy: 0.5645\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.4125 - accuracy: 0.9516\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.0522 - accuracy: 0.9839\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0525 - accuracy: 0.9839\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.0388 - accuracy: 0.9839\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.0262 - accuracy: 0.9839\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.0197 - accuracy: 0.9839\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 661us/step - loss: 0.0159 - accuracy: 0.9919\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0145 - accuracy: 0.9919\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 994us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 4.2155e-04 - accuracy: 1.0000\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 7.6340e-04 - accuracy: 1.0000\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.5720e-04 - accuracy: 1.0000\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.3401e-04 - accuracy: 1.0000\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.3857e-05 - accuracy: 1.0000\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 3.4726e-05 - accuracy: 1.0000\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.8107e-05 - accuracy: 1.0000\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 673us/step - loss: 2.5901e-05 - accuracy: 1.0000\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 2.1935e-05 - accuracy: 1.0000\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.0886e-05 - accuracy: 1.0000\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.8545e-05 - accuracy: 1.0000\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.7161e-05 - accuracy: 1.0000\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.5938e-05 - accuracy: 1.0000\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.5320e-05 - accuracy: 1.0000\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.4186e-05 - accuracy: 1.0000\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.3655e-05 - accuracy: 1.0000\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.2738e-05 - accuracy: 1.0000\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 1.2262e-05 - accuracy: 1.0000\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - ETA: 0s - loss: 3.9509e-06 - accuracy: 1.00 - 0s 500us/step - loss: 1.1757e-05 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.1316e-05 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 508us/step - loss: 1.0840e-05 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0436e-05 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 1.0079e-05 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 9.6661e-06 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7DBA98B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.2297 - accuracy: 0.9630\n",
      "Epoch 1/35\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2403 - accuracy: 0.2857WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "6/6 [==============================] - 0s 838us/step - loss: 0.7744 - accuracy: 0.5968\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 670us/step - loss: 0.5270 - accuracy: 0.9597\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 664us/step - loss: 1.1408 - accuracy: 0.8790\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.8237 - accuracy: 0.9597\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.6533 - accuracy: 0.9355\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 830us/step - loss: 0.2001 - accuracy: 0.9516\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 838us/step - loss: 0.1412 - accuracy: 0.9516\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.5501 - accuracy: 0.9516\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 669us/step - loss: 0.3441 - accuracy: 0.9032\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5516 - accuracy: 0.9113\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.2129 - accuracy: 0.9435\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.3065 - accuracy: 0.9758\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.3144 - accuracy: 0.9355\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.1812 - accuracy: 0.9597\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 504us/step - loss: 0.1649 - accuracy: 0.9597\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.1765 - accuracy: 0.9516\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0905 - accuracy: 0.9758\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.1301 - accuracy: 0.9677\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.2120 - accuracy: 0.9516\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0930 - accuracy: 0.9758\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.0926 - accuracy: 0.9758\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0912 - accuracy: 0.9758\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.0936 - accuracy: 0.9758\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0916 - accuracy: 0.9758\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 672us/step - loss: 0.0905 - accuracy: 0.9758\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0907 - accuracy: 0.9758\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.0901 - accuracy: 0.9758\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 672us/step - loss: 0.0898 - accuracy: 0.9758\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0895 - accuracy: 0.9758\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0893 - accuracy: 0.9758\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.0898 - accuracy: 0.9758\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 672us/step - loss: 0.0904 - accuracy: 0.9758\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0892 - accuracy: 0.9758\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.0897 - accuracy: 0.9758\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0894 - accuracy: 0.9758\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB02339160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 655us/step - loss: 0.3108 - accuracy: 0.9259\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 845us/step - loss: 0.9700 - accuracy: 0.5565\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 670us/step - loss: 0.2185 - accuracy: 0.9597\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 1.6761 - accuracy: 0.9113\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.5106 - accuracy: 0.8790\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.2573 - accuracy: 0.9435\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 827us/step - loss: 0.2336 - accuracy: 0.9274\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 835us/step - loss: 0.1416 - accuracy: 0.9597\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.3664 - accuracy: 0.9677\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0728 - accuracy: 0.9839\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0805 - accuracy: 0.9839\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0938 - accuracy: 0.9677\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.1557 - accuracy: 0.9516\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.1567 - accuracy: 0.9516\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.1431 - accuracy: 0.9677\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0747 - accuracy: 0.9839\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.0669 - accuracy: 0.9919\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 505us/step - loss: 0.0705 - accuracy: 0.9839\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 672us/step - loss: 0.0507 - accuracy: 0.9839\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.1045 - accuracy: 0.9597\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.1269 - accuracy: 0.9677\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.0629 - accuracy: 0.9839\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.1398 - accuracy: 0.9677\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.1675 - accuracy: 0.9758\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 505us/step - loss: 0.0895 - accuracy: 0.9758\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.1787 - accuracy: 0.9677\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0941 - accuracy: 0.9758\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 503us/step - loss: 0.0797 - accuracy: 0.9758\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.0641 - accuracy: 0.9839\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.0675 - accuracy: 0.9839\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0646 - accuracy: 0.9839\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 674us/step - loss: 0.0637 - accuracy: 0.9839\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 673us/step - loss: 0.0628 - accuracy: 0.9839\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.0630 - accuracy: 0.9839\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.0640 - accuracy: 0.9839\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 661us/step - loss: 0.0629 - accuracy: 0.9839\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7D7FF3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 678us/step - loss: 0.0714 - accuracy: 0.9815\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 1.0565 - accuracy: 0.5161\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.7984\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.3277 - accuracy: 0.9435\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.2337 - accuracy: 0.9597\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.3231 - accuracy: 0.9677\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 827us/step - loss: 0.0867 - accuracy: 0.9839\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.0445 - accuracy: 0.9919\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 660us/step - loss: 0.0636 - accuracy: 0.9839\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 498us/step - loss: 0.1070 - accuracy: 0.9839\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.1358 - accuracy: 0.9677\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.3050 - accuracy: 0.8952\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 2.1651 - accuracy: 0.7823\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 2.4589 - accuracy: 0.8710\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.2382 - accuracy: 0.9355\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 661us/step - loss: 0.7664 - accuracy: 0.9032\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.8239 - accuracy: 0.8145\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.1519 - accuracy: 0.4758\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.8421 - accuracy: 0.6129\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.6597 - accuracy: 0.6532\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5378 - accuracy: 0.6290\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.5552 - accuracy: 0.6129\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 0.6268 - accuracy: 0.6774\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5371 - accuracy: 0.6774\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 0.5122 - accuracy: 0.6855\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.5107 - accuracy: 0.6855\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 674us/step - loss: 0.5086 - accuracy: 0.6855\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 505us/step - loss: 0.5315 - accuracy: 0.6774\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5115 - accuracy: 0.6855\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5125 - accuracy: 0.6855\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5149 - accuracy: 0.6855\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5087 - accuracy: 0.6855\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5110 - accuracy: 0.6855\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5131 - accuracy: 0.6855\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5117 - accuracy: 0.6855\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5110 - accuracy: 0.6855\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7D63E040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1.4152 - accuracy: 0.5926\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.2478 - accuracy: 0.4677\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 799us/step - loss: 0.6298 - accuracy: 0.7500\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 832us/step - loss: 0.6066 - accuracy: 0.9113\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.3212 - accuracy: 0.9113\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2109 - accuracy: 0.9355\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.1559 - accuracy: 0.9677\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.1369 - accuracy: 0.9597\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.3845 - accuracy: 0.9435\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.3005 - accuracy: 0.9274\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7391 - accuracy: 0.9355\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2698 - accuracy: 0.9032\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.3676 - accuracy: 0.8387\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.3865 - accuracy: 0.7823\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.3704 - accuracy: 0.7500\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 827us/step - loss: 0.3430 - accuracy: 0.8226\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.3256 - accuracy: 0.8306\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.3193 - accuracy: 0.8306\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.3124 - accuracy: 0.8468\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.2905 - accuracy: 0.8629\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.2783 - accuracy: 0.8710\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.2410 - accuracy: 0.9032\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.2448 - accuracy: 0.9113\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2154 - accuracy: 0.9194\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.2275 - accuracy: 0.9113\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2265 - accuracy: 0.9113\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2287 - accuracy: 0.9113\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2262 - accuracy: 0.9113\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.2270 - accuracy: 0.9113\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 670us/step - loss: 0.2307 - accuracy: 0.9113\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.2267 - accuracy: 0.9113\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2273 - accuracy: 0.9113\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2263 - accuracy: 0.9113\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2254 - accuracy: 0.9113\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.2255 - accuracy: 0.9113\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 508us/step - loss: 0.2282 - accuracy: 0.9113\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7EF5DDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.2251 - accuracy: 0.9074\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3477 - accuracy: 0.4919\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 854us/step - loss: 0.4522 - accuracy: 0.8468\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 999us/step - loss: 0.5673 - accuracy: 0.8145\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.7823\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.4210 - accuracy: 0.7177\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 830us/step - loss: 0.4323 - accuracy: 0.7581\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.6613\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.4316 - accuracy: 0.7742\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 995us/step - loss: 0.3832 - accuracy: 0.8226\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.3743 - accuracy: 0.8306\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.3621 - accuracy: 0.8387\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.3627 - accuracy: 0.8387\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.3934 - accuracy: 0.8226\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 504us/step - loss: 0.3224 - accuracy: 0.8629\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.2206 - accuracy: 0.9274\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.2854 - accuracy: 0.9435\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 7.5032 - accuracy: 0.8952\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 0.9616 - accuracy: 0.7177\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.6964 - accuracy: 0.6452\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 1.3468 - accuracy: 0.5645\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 660us/step - loss: 0.7083 - accuracy: 0.6532\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7035 - accuracy: 0.6210\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.7163 - accuracy: 0.5484\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7046 - accuracy: 0.6532\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.6781 - accuracy: 0.6290\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.6766 - accuracy: 0.6452\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.6872 - accuracy: 0.6129\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.7242 - accuracy: 0.6048\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.6896 - accuracy: 0.6532\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.6948 - accuracy: 0.6210\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7267 - accuracy: 0.6290\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.7200 - accuracy: 0.6210\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7929 - accuracy: 0.5968\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.7212 - accuracy: 0.6371\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 669us/step - loss: 0.7184 - accuracy: 0.5726\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7ED1AA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.8157 - accuracy: 0.5741\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 2.3111 - accuracy: 0.5565\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.3766 - accuracy: 0.9032\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 999us/step - loss: 0.5363 - accuracy: 0.8790\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.2420 - accuracy: 0.9597\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 673us/step - loss: 0.7027 - accuracy: 0.8629\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.1641 - accuracy: 0.9597\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5527 - accuracy: 0.9597\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.5814 - accuracy: 0.7823\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.5091 - accuracy: 0.7177\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 503us/step - loss: 0.6286 - accuracy: 0.6774\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.5358 - accuracy: 0.6613\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5780 - accuracy: 0.5806\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5539 - accuracy: 0.6774\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.4685 - accuracy: 0.6774\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.3930 - accuracy: 0.8629\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 495us/step - loss: 1.0776 - accuracy: 0.7742\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 506us/step - loss: 0.4994 - accuracy: 0.7339\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.8283 - accuracy: 0.6210\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0596 - accuracy: 0.5484\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.8245 - accuracy: 0.6774\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.3562 - accuracy: 0.6452\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0788 - accuracy: 0.6532\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 5.2062 - accuracy: 0.5403\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.2165 - accuracy: 0.4677\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0143 - accuracy: 0.4677\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.1526 - accuracy: 0.4274\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0505 - accuracy: 0.3790\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0662 - accuracy: 0.3548\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0661 - accuracy: 0.4274\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0652 - accuracy: 0.4274\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0677 - accuracy: 0.3145\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 660us/step - loss: 1.0628 - accuracy: 0.3871\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0715 - accuracy: 0.4274\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 505us/step - loss: 1.0496 - accuracy: 0.3629\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0535 - accuracy: 0.3952\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB04A2C4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1.0914 - accuracy: 0.3333\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 840us/step - loss: 3.9557 - accuracy: 0.3387\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.6758 - accuracy: 0.6129\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0613 - accuracy: 0.6532\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.6340 - accuracy: 0.7097\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7339\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.5107 - accuracy: 0.7339\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 828us/step - loss: 0.5299 - accuracy: 0.7258\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5055 - accuracy: 0.7339\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5007 - accuracy: 0.7339\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.5017 - accuracy: 0.7339\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 837us/step - loss: 0.4997 - accuracy: 0.7339\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5000 - accuracy: 0.7339\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 832us/step - loss: 0.5059 - accuracy: 0.7339\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.4979 - accuracy: 0.7339\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5048 - accuracy: 0.7339\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5010 - accuracy: 0.7339\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5111 - accuracy: 0.7339\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.4981 - accuracy: 0.7339\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5068 - accuracy: 0.7339\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.4997 - accuracy: 0.7339\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5001 - accuracy: 0.7339\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5044 - accuracy: 0.7339\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.4985 - accuracy: 0.7339\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5064 - accuracy: 0.7339\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5045 - accuracy: 0.7339\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.5008 - accuracy: 0.7339\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5031 - accuracy: 0.7339\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.5029 - accuracy: 0.7339\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 673us/step - loss: 0.5059 - accuracy: 0.7339\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5035 - accuracy: 0.7339\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5068 - accuracy: 0.7339\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.4997 - accuracy: 0.7339\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5044 - accuracy: 0.7339\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.5001 - accuracy: 0.7339\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5218 - accuracy: 0.7339\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7D768790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.4853 - accuracy: 0.7037\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 837us/step - loss: 3.7286 - accuracy: 0.3871\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 673us/step - loss: 0.8860 - accuracy: 0.5645\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.8724 - accuracy: 0.6048\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 499us/step - loss: 1.1543 - accuracy: 0.6371\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.6695 - accuracy: 0.6532\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.7735 - accuracy: 0.6694\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.8027 - accuracy: 0.5806\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 829us/step - loss: 0.7251 - accuracy: 0.6371\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 670us/step - loss: 0.5952 - accuracy: 0.6935\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.6054 - accuracy: 0.6855\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.5800 - accuracy: 0.6048\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.5540 - accuracy: 0.6935\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 1.6012 - accuracy: 0.7016\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.6509 - accuracy: 0.6694\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 670us/step - loss: 0.5033 - accuracy: 0.7177\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5255 - accuracy: 0.7097\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5604 - accuracy: 0.5887\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 830us/step - loss: 0.5477 - accuracy: 0.7016\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5497 - accuracy: 0.7016\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5467 - accuracy: 0.7016\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5480 - accuracy: 0.7016\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.5440 - accuracy: 0.7016\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5497 - accuracy: 0.7016\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5569 - accuracy: 0.6048\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5560 - accuracy: 0.7016\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5481 - accuracy: 0.7016\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 675us/step - loss: 0.5508 - accuracy: 0.6613\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 497us/step - loss: 0.5445 - accuracy: 0.7016\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 658us/step - loss: 0.5554 - accuracy: 0.7016\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5466 - accuracy: 0.6774\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.5490 - accuracy: 0.6371\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5451 - accuracy: 0.7016\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.5526 - accuracy: 0.7016\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.5427 - accuracy: 0.7016\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5599 - accuracy: 0.7016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB04A2C670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.6582 - accuracy: 0.6481\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 3.1473 - accuracy: 0.4758\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.1109 - accuracy: 0.5484\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.8345 - accuracy: 0.5484\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.6232 - accuracy: 0.6855\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 836us/step - loss: 0.5708 - accuracy: 0.6371\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 836us/step - loss: 0.7195 - accuracy: 0.5968\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 998us/step - loss: 1.0098 - accuracy: 0.5645\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 828us/step - loss: 0.9884 - accuracy: 0.4677\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 832us/step - loss: 0.8848 - accuracy: 0.5323\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.7991 - accuracy: 0.6210\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.9799 - accuracy: 0.5323\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 1.0556 - accuracy: 0.4113\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.1367 - accuracy: 0.4194\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 828us/step - loss: 1.0353 - accuracy: 0.4597\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0654 - accuracy: 0.4597\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0521 - accuracy: 0.4597\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0546 - accuracy: 0.4597\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 672us/step - loss: 1.0450 - accuracy: 0.3710\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0497 - accuracy: 0.4597\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 672us/step - loss: 1.0357 - accuracy: 0.4597\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 507us/step - loss: 1.0418 - accuracy: 0.4597\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 670us/step - loss: 1.0464 - accuracy: 0.4597\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0447 - accuracy: 0.4597\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0551 - accuracy: 0.4597\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0572 - accuracy: 0.4597\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0372 - accuracy: 0.4597\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0411 - accuracy: 0.4597\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0382 - accuracy: 0.4597\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0459 - accuracy: 0.4194\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0483 - accuracy: 0.4597\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 673us/step - loss: 1.0421 - accuracy: 0.4597\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0389 - accuracy: 0.4597\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0466 - accuracy: 0.4597\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0380 - accuracy: 0.3710\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0500 - accuracy: 0.4597\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB02369700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 0s/step - loss: 1.0166 - accuracy: 0.4259\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 3.3469 - accuracy: 0.6210\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 4.2501 - accuracy: 0.7984\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 2.8426 - accuracy: 0.5968\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.8001 - accuracy: 0.6774\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.7872 - accuracy: 0.6452\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.6072 - accuracy: 0.6694\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.6638 - accuracy: 0.7258\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 502us/step - loss: 0.6344 - accuracy: 0.6371\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.5987 - accuracy: 0.6532\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.7597 - accuracy: 0.7177\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5454 - accuracy: 0.6371\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.4995 - accuracy: 0.7258\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.6023 - accuracy: 0.6694\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 1000us/step - loss: 0.4462 - accuracy: 0.7581\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 830us/step - loss: 0.5150 - accuracy: 0.7177\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 0.5839 - accuracy: 0.6855\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 836us/step - loss: 0.5820 - accuracy: 0.6210\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 831us/step - loss: 0.5362 - accuracy: 0.6935\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5193 - accuracy: 0.6694\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.4945 - accuracy: 0.7016\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.6759 - accuracy: 0.6935\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.8895 - accuracy: 0.4597\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.8385 - accuracy: 0.5161\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 0.8232 - accuracy: 0.5968\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7443 - accuracy: 0.5806\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 661us/step - loss: 0.7555 - accuracy: 0.5726\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.7470 - accuracy: 0.5726\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7296 - accuracy: 0.6048\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.7357 - accuracy: 0.5806\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7286 - accuracy: 0.5645\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 505us/step - loss: 0.7232 - accuracy: 0.5403\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7290 - accuracy: 0.5403\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.7218 - accuracy: 0.5403\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7244 - accuracy: 0.5565\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 664us/step - loss: 0.7449 - accuracy: 0.5806\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB7D5834C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.6548 - accuracy: 0.5741\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.6103 - accuracy: 0.3871\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 440us/step - loss: 1.2315 - accuracy: 0.3468\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.1284 - accuracy: 0.3145\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 1.1396 - accuracy: 0.4194\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 1.1108 - accuracy: 0.3790\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.3871\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 1.1211 - accuracy: 0.4274\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 1.1007 - accuracy: 0.3710\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 834us/step - loss: 1.0955 - accuracy: 0.3790\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0870 - accuracy: 0.4274\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0937 - accuracy: 0.4274\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0849 - accuracy: 0.4274\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0860 - accuracy: 0.4274\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 661us/step - loss: 1.0805 - accuracy: 0.4274\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.1002 - accuracy: 0.4274\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0998 - accuracy: 0.4274\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 661us/step - loss: 1.0964 - accuracy: 0.4274\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 668us/step - loss: 1.0847 - accuracy: 0.4274\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 660us/step - loss: 1.0934 - accuracy: 0.4274\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 1.0800 - accuracy: 0.4274\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 669us/step - loss: 1.0852 - accuracy: 0.4274\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0922 - accuracy: 0.4274\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0919 - accuracy: 0.3790\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0947 - accuracy: 0.4274\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.1006 - accuracy: 0.3710\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 496us/step - loss: 1.0817 - accuracy: 0.4274\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0898 - accuracy: 0.4274\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 506us/step - loss: 1.0848 - accuracy: 0.3710\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0952 - accuracy: 0.3629\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0919 - accuracy: 0.4274\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.0961 - accuracy: 0.3871\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.0824 - accuracy: 0.4274\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 661us/step - loss: 1.0950 - accuracy: 0.4274\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 672us/step - loss: 1.0827 - accuracy: 0.3387\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 1.1102 - accuracy: 0.4274\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB023390D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 656us/step - loss: 1.1685 - accuracy: 0.3333\n",
      "Epoch 1/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 6.0719 - accuracy: 0.3548\n",
      "Epoch 2/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 1.4595 - accuracy: 0.4355\n",
      "Epoch 3/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.7235 - accuracy: 0.5726\n",
      "Epoch 4/35\n",
      "6/6 [==============================] - 0s 833us/step - loss: 0.6604 - accuracy: 0.6452\n",
      "Epoch 5/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 0.5853 - accuracy: 0.7177\n",
      "Epoch 6/35\n",
      "6/6 [==============================] - 0s 659us/step - loss: 0.5303 - accuracy: 0.7339\n",
      "Epoch 7/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5277 - accuracy: 0.7339\n",
      "Epoch 8/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.4998 - accuracy: 0.7339\n",
      "Epoch 9/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.4999 - accuracy: 0.7339\n",
      "Epoch 10/35\n",
      "6/6 [==============================] - 0s 666us/step - loss: 0.4985 - accuracy: 0.7339\n",
      "Epoch 11/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.4983 - accuracy: 0.7339\n",
      "Epoch 12/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5007 - accuracy: 0.7339\n",
      "Epoch 13/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5057 - accuracy: 0.7339\n",
      "Epoch 14/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.4979 - accuracy: 0.7339\n",
      "Epoch 15/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5058 - accuracy: 0.7339\n",
      "Epoch 16/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5014 - accuracy: 0.7339\n",
      "Epoch 17/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5131 - accuracy: 0.7339\n",
      "Epoch 18/35\n",
      "6/6 [==============================] - 0s 671us/step - loss: 0.4981 - accuracy: 0.7339\n",
      "Epoch 19/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5083 - accuracy: 0.7339\n",
      "Epoch 20/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5004 - accuracy: 0.7339\n",
      "Epoch 21/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5001 - accuracy: 0.7339\n",
      "Epoch 22/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5047 - accuracy: 0.7339\n",
      "Epoch 23/35\n",
      "6/6 [==============================] - 0s 672us/step - loss: 0.4987 - accuracy: 0.7339\n",
      "Epoch 24/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5053 - accuracy: 0.7339\n",
      "Epoch 25/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5071 - accuracy: 0.7339\n",
      "Epoch 26/35\n",
      "6/6 [==============================] - 0s 505us/step - loss: 0.5012 - accuracy: 0.7339\n",
      "Epoch 27/35\n",
      "6/6 [==============================] - 0s 674us/step - loss: 0.5063 - accuracy: 0.7339\n",
      "Epoch 28/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5054 - accuracy: 0.7339\n",
      "Epoch 29/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.5089 - accuracy: 0.7339\n",
      "Epoch 30/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.5044 - accuracy: 0.7339\n",
      "Epoch 31/35\n",
      "6/6 [==============================] - 0s 499us/step - loss: 0.5106 - accuracy: 0.7339\n",
      "Epoch 32/35\n",
      "6/6 [==============================] - 0s 663us/step - loss: 0.4996 - accuracy: 0.7339\n",
      "Epoch 33/35\n",
      "6/6 [==============================] - 0s 500us/step - loss: 0.5079 - accuracy: 0.7339\n",
      "Epoch 34/35\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.4984 - accuracy: 0.7339\n",
      "Epoch 35/35\n",
      "6/6 [==============================] - 0s 662us/step - loss: 0.5269 - accuracy: 0.7339\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CB0765A3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.4959 - accuracy: 0.6852\n"
     ]
    }
   ],
   "source": [
    "learning_rate=np.linspace(0.0005,0.5,20)\n",
    "accuracy_learning_rate=[]\n",
    "for i in learning_rate:\n",
    "    model=tf.keras.models.Sequential([tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                         tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(3,activation=tf.nn.softmax)])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=i),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(X_train,Y_train,epochs=35,batch_size=21)\n",
    "    accuracy_learning_rate.append(model.evaluate(X_test,Y_test,batch_size=21))\n",
    "df1=pd.DataFrame(accuracy_learning_rate,columns=['loss','Accuracy']) #storing all the accuries in the Dataframe\n",
    "df1[\"learning rate\"]=[i for i in learning_rate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>learning rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.091424</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.342263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.168523</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.473711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.016647</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.421132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.654827</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.447421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.815738</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.315974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.415239</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.263395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.658158</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.394842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.495903</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.485326</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.368553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.225148</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.289684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.310827</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.210816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.564147</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.205429</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.131947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.026789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.229742</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.184526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.247805</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.158237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.028743</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.105658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.155799</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.079368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.157944</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.053079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.071391</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.237105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  Accuracy  learning rate\n",
       "13  1.091424  0.333333       0.342263\n",
       "18  1.168523  0.333333       0.473711\n",
       "16  1.016647  0.425926       0.421132\n",
       "17  0.654827  0.574074       0.447421\n",
       "12  0.815738  0.574074       0.315974\n",
       "10  1.415239  0.592593       0.263395\n",
       "15  0.658158  0.648148       0.394842\n",
       "19  0.495903  0.685185       0.500000\n",
       "14  0.485326  0.703704       0.368553\n",
       "11  0.225148  0.907407       0.289684\n",
       "8   0.310827  0.925926       0.210816\n",
       "0   0.564147  0.944444       0.000500\n",
       "5   0.205429  0.962963       0.131947\n",
       "1   0.101600  0.962963       0.026789\n",
       "7   0.229742  0.962963       0.184526\n",
       "6   0.247805  0.981481       0.158237\n",
       "4   1.028743  0.981481       0.105658\n",
       "3   0.155799  0.981481       0.079368\n",
       "2   0.157944  0.981481       0.053079\n",
       "9   0.071391  0.981481       0.237105"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sort_values(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx=df1[df1[\"Accuracy\"]==df1.max()[\"Accuracy\"]]\n",
    "_ = plt.plot(df1[\"learning rate\"],df1['Accuracy'],'b')\n",
    "_ = plt.plot(idx.iloc[0,2],idx.iloc[0,1],'ro')\n",
    "_ = plt.annotate(f'Optimal learning rate is  {idx.iloc[0,2]:.3f}',(idx.iloc[0,2],idx.iloc[0,1]))\n",
    "_ = plt.xlabel('Learning Rate')\n",
    "_ = plt.ylabel('Accuracy')\n",
    "_ = plt.title('Learning Rate v.s. Test Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>The optimal learning rate is 0.053 there are actually 5 learning rates with optimal accuracy, all of these are residing in range of 0.04 to 0.15</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 0s 720us/step - loss: 0.3192 - accuracy: 0.9516\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 679us/step - loss: 0.0853 - accuracy: 0.9677\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 680us/step - loss: 0.1479 - accuracy: 0.9677\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 679us/step - loss: 0.0740 - accuracy: 0.9758\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 598us/step - loss: 0.0352 - accuracy: 0.9839\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 519us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 520us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 520us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 560us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 560us/step - loss: 8.4773e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 559us/step - loss: 6.0670e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 562us/step - loss: 4.6435e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 560us/step - loss: 3.8945e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 560us/step - loss: 3.1744e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 558us/step - loss: 2.6626e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 520us/step - loss: 2.3550e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 520us/step - loss: 2.0215e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 520us/step - loss: 1.7638e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 560us/step - loss: 1.5708e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 560us/step - loss: 1.3897e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBEF414B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11/11 [==============================] - 0s 451us/step - loss: 0.1538 - accuracy: 0.9630\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 691us/step - loss: 0.6409 - accuracy: 0.7661\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 849us/step - loss: 0.1481 - accuracy: 0.9677\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 689us/step - loss: 0.0977 - accuracy: 0.9758\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 613us/step - loss: 0.0740 - accuracy: 0.9758\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 536us/step - loss: 0.0560 - accuracy: 0.9758\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.0164 - accuracy: 0.9919\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.0203 - accuracy: 0.9919\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 615us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 615us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 536us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 615us/step - loss: 7.9948e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 615us/step - loss: 5.9231e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 612us/step - loss: 4.8888e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 692us/step - loss: 3.9776e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 692us/step - loss: 3.3137e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 618us/step - loss: 2.9733e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 541us/step - loss: 2.5484e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 560us/step - loss: 2.2574e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 618us/step - loss: 1.9952e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 615us/step - loss: 1.8030e-04 - accuracy: 1.0000\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.6879e-05 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "6/6 [==============================] - 0s 660us/step - loss: 0.2860 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 0s 892us/step - loss: 0.9289 - accuracy: 0.5806\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.9113\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.0721 - accuracy: 0.9758\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 774us/step - loss: 0.0242 - accuracy: 0.9919\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 669us/step - loss: 5.6491e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 663us/step - loss: 4.1466e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 551us/step - loss: 3.3656e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 555us/step - loss: 2.8694e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 774us/step - loss: 2.5878e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 666us/step - loss: 2.3806e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 555us/step - loss: 2.1924e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 556us/step - loss: 2.0080e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 662us/step - loss: 1.8535e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 555us/step - loss: 1.7036e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 664us/step - loss: 1.6151e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 445us/step - loss: 1.4859e-04 - accuracy: 1.0000\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.1261 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0105 - accuracy: 0.4274\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 667us/step - loss: 0.4707 - accuracy: 0.8387\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 835us/step - loss: 0.1480 - accuracy: 0.9597\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 673us/step - loss: 0.0385 - accuracy: 0.9919\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 661us/step - loss: 0.0891 - accuracy: 0.9839\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 665us/step - loss: 0.0156 - accuracy: 0.9919\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 493us/step - loss: 0.0586 - accuracy: 0.9839\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 499us/step - loss: 8.8268e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 659us/step - loss: 8.3292e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 659us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 661us/step - loss: 3.3895e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 667us/step - loss: 2.1375e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 777us/step - loss: 1.8486e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 727us/step - loss: 1.5444e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 671us/step - loss: 1.2846e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 502us/step - loss: 1.1271e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 666us/step - loss: 1.0605e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 662us/step - loss: 9.3613e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 505us/step - loss: 8.9423e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 715us/step - loss: 8.2511e-05 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5.9325e-04 - accuracy: 1.0000\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9378 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 808us/step - loss: 0.5756 - accuracy: 0.6613\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 811us/step - loss: 0.3816 - accuracy: 0.6855\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.9274\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1628 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0634 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 802us/step - loss: 7.1086e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 810us/step - loss: 2.2263e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 795us/step - loss: 9.8278e-05 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 800us/step - loss: 5.3923e-05 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 799us/step - loss: 3.9028e-05 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3.1026e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 595us/step - loss: 2.5318e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 800us/step - loss: 2.2851e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 600us/step - loss: 2.0810e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.9135e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.8108e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 606us/step - loss: 1.7230e-05 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 668us/step - loss: 0.2105 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 993us/step - loss: 0.9296 - accuracy: 0.6290\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.5791 - accuracy: 0.8710\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.3462 - accuracy: 0.9194\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.1551 - accuracy: 0.9758\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0562 - accuracy: 0.9839\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 3.4482e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 6.1259e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 4.7500e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 5.7891e-05 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 499us/step - loss: 3.5804e-05 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 3.2520e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 3.0782e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 2.9359e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 2.7217e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 2.3572e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 2.1756e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 1.9033e-05 - accuracy: 1.0000\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0844 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.9797 - accuracy: 0.4919\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.5881 - accuracy: 0.8710\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 756us/step - loss: 0.2365 - accuracy: 0.9516\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0983 - accuracy: 0.9758\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.0575 - accuracy: 0.9919\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0247 - accuracy: 0.9839\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0164 - accuracy: 0.9919\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 7.4595e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 5.0975e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 5.3731e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 2.8602e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 752us/step - loss: 1.4119e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 1.0865e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 8.9551e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 7.1748e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 753us/step - loss: 6.3912e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 502us/step - loss: 5.1113e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBEF348670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.2122 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 999us/step - loss: 1.0696 - accuracy: 0.3790\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.8123 - accuracy: 0.5887\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.8871\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.9435\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.9597\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 664us/step - loss: 0.1355 - accuracy: 0.9758\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.1133 - accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 660us/step - loss: 0.0865 - accuracy: 0.9839\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 663us/step - loss: 0.0709 - accuracy: 0.9839\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9839\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 669us/step - loss: 0.0493 - accuracy: 0.9839\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 334us/step - loss: 0.0449 - accuracy: 0.9839\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 675us/step - loss: 0.0320 - accuracy: 0.9839\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0309 - accuracy: 0.9839\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0337 - accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 999us/step - loss: 0.0286 - accuracy: 0.9839\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.0493 - accuracy: 0.9919\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.0118 - accuracy: 0.9919\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9919\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0203 - accuracy: 0.9919\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBEF3480D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.2775 - accuracy: 0.9630\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 996us/step - loss: 0.8720 - accuracy: 0.6532\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 664us/step - loss: 0.4847 - accuracy: 0.8226\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 659us/step - loss: 0.2636 - accuracy: 0.9677\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 664us/step - loss: 0.1098 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5.7045e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 1.0414e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4.5876e-05 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 2.0247e-05 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1.5069e-05 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 1.1905e-05 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1.0966e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9.9418e-06 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 9.5534e-06 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8.9055e-06 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8.4730e-06 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 675us/step - loss: 8.0991e-06 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 7.7080e-06 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBEF129310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.2061 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 659us/step - loss: 1.0106 - accuracy: 0.3871\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 659us/step - loss: 0.6841 - accuracy: 0.6774\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.4341 - accuracy: 0.8871\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 660us/step - loss: 0.2531 - accuracy: 0.9435\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 662us/step - loss: 0.1183 - accuracy: 0.9839\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.0755 - accuracy: 0.9839\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 662us/step - loss: 0.0168 - accuracy: 0.9919\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8.6906e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6.0712e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4.5675e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 3.5613e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 2.5901e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 332us/step - loss: 2.0138e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1.3523e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 994us/step - loss: 9.6112e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 7.2649e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5.4247e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBF18F4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.1987 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.4221 - accuracy: 0.2661\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 999us/step - loss: 0.8731 - accuracy: 0.5403\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 993us/step - loss: 0.6705 - accuracy: 0.6532\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 670us/step - loss: 0.5204 - accuracy: 0.6694\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.4258 - accuracy: 0.7258\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 675us/step - loss: 0.3317 - accuracy: 0.9435\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.2573 - accuracy: 0.9839\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.2069 - accuracy: 0.9839\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9839\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.1200 - accuracy: 0.9839\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 675us/step - loss: 0.0900 - accuracy: 0.9839\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 665us/step - loss: 0.0660 - accuracy: 0.9839\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0452 - accuracy: 0.9919\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 671us/step - loss: 0.0319 - accuracy: 0.9919\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 661us/step - loss: 0.0231 - accuracy: 0.9919\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 677us/step - loss: 0.0178 - accuracy: 0.9919\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 674us/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 659us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 665us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 660us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBEF2EC430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.0284 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9717 - accuracy: 0.4274\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.6614 - accuracy: 0.8629\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.9113\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 521us/step - loss: 0.2055 - accuracy: 0.9516\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9758\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 987us/step - loss: 0.0588 - accuracy: 0.9839\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9839\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0447 - accuracy: 0.9839\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9919\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9919\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 0.9919\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 501us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 4.2093e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBF2F0A4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.1625 - accuracy: 0.3387\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 491us/step - loss: 0.8349 - accuracy: 0.7661\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.8629\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.9194\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.2114 - accuracy: 0.9355\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.1146 - accuracy: 0.9597\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 994us/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 502us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 886us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6450e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.5570e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 3.5228e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 998us/step - loss: 2.8228e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 991us/step - loss: 2.1233e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 1.7070e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 1.3119e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE948CEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.0662 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1057 - accuracy: 0.3871\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8878 - accuracy: 0.6935\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.6656 - accuracy: 0.7339\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 506us/step - loss: 0.4744 - accuracy: 0.7339\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.7419\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.2872 - accuracy: 0.9113\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9597\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9919\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.1363 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 497us/step - loss: 0.0708 - accuracy: 0.9919\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9919\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.0040e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 6.1448e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBEF2ECCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2518 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 1.2154 - accuracy: 0.2984\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.8093 - accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.6153 - accuracy: 0.8790\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 518us/step - loss: 0.4584 - accuracy: 0.9194\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 993us/step - loss: 0.3181 - accuracy: 0.9274\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 491us/step - loss: 0.2114 - accuracy: 0.9435\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.1561 - accuracy: 0.9435\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9516\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 504us/step - loss: 0.0988 - accuracy: 0.9677\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 516us/step - loss: 0.0820 - accuracy: 0.9758\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 982us/step - loss: 0.0635 - accuracy: 0.9839\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 510us/step - loss: 0.0444 - accuracy: 0.9839\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0334 - accuracy: 0.9919\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 489us/step - loss: 0.0264 - accuracy: 0.9919\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0171 - accuracy: 0.9919\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 977us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 497us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 510us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 506us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBF0670040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1858 - accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "kk=np.linspace(5,80,15)\n",
    "batch_size=[int(i) for i in kk]\n",
    "accuracy_batch_size=[]\n",
    "for i in batch_size:\n",
    "    model=tf.keras.models.Sequential([tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                         tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(3,activation=tf.nn.softmax)])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.025),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(X_train,Y_train,epochs=20,batch_size=i)\n",
    "    accuracy_batch_size.append(model.evaluate(X_test,Y_test,batch_size=i))\n",
    "df2=pd.DataFrame(accuracy_batch_size,columns=['loss','Accuracy'])#storing all the accuries in the Dataframe\n",
    "df2[\"batch size\"]=[i for i in batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>batch size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153818</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.277499</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286038</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.126087</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210518</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.084366</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.212241</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.206078</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.198665</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.196631</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.066155</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.251810</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.185787</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  Accuracy  batch size\n",
       "0   0.153818  0.962963           5\n",
       "7   0.277499  0.962963          42\n",
       "1   0.286038  0.981481          10\n",
       "2   0.126087  0.981481          15\n",
       "4   0.210518  0.981481          26\n",
       "5   0.084366  0.981481          31\n",
       "6   0.212241  0.981481          37\n",
       "8   0.206078  0.981481          47\n",
       "9   0.198665  0.981481          53\n",
       "10  0.028363  0.981481          58\n",
       "11  0.196631  0.981481          63\n",
       "12  0.066155  0.981481          69\n",
       "13  0.251810  0.981481          74\n",
       "14  0.185787  0.981481          80\n",
       "3   0.000593  1.000000          21"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sort_values(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA490lEQVR4nO3debzUZf3//8cTEFkEQUBCUEBFZD/CDLnkUmYuqSi2aJZgkllp2q/Nr34/aZ82W/lYmqS5laalZZEfv5pRHa00Z8DDKsguCLLKoqDA4fX743oPDMOcc2YOM2fmzLzut9vcZt77633OnPN6v6/rfV2XzAznnHMuV21KHYBzzrnWxROHc865vHjicM45lxdPHM455/LiicM551xePHE455zLiycOlxdJyyR9sAWOc6ukhwqwnymS/qsQMTnnAk8crsVI+oekSS15TDO7xsy+1ZLHPBCS5kp6K3rVS3onbfqmZuzvAUnfzmE9SVoiaV7zInfVpF2pA3DO7WVmw1KfJf0DeMjMftkChz4NOBxoJyluZokWOCYAktqZ2a6WOp47cH7H4ZojLmmepDcl3S+pA4Ck7pKelLQuWvakpH7Rsu8ApwJ3RFfPd0Tzh0l6VtJGSWsyrqrbS/qVpK3RlXgsWzDR1fJkSWslbZY0S9LwaNmeK25Jf067en9L0m5JE6Nlx6fFsUDSxxo41qWSkhnzviRpapZ1J0ZX8VslLZV0eX4/5v3292lJr0Q/22ck9W/s/CVdDVwOfC063z83svsJwJ+Ap6LP6cfN+juS1FbSTZIWR+c4XdKRkgZIMknt0vax524z+rn8K4p5I3CrpGMk/U3SBknrJT0sqVva9kdK+kP03dog6Q5JB0cxjUhb73BJ2yX1OpCftWuCmfnLXzm/gGXAHOBI4DDgX8C3o2U9gEuATkAX4DHgj2nb/gOYlDbdBVgNfBnoEE2/N1p2K/AOcB7QFvge8GIDMZ0NTAe6AQKGAH2iZQ+k4svY5hxgVXQenYEVwJWEu/DRwHpgWJbtOgFbgUFp8xLApRnrdQa2AIOj6T7Z9tfEz3rPzwu4CFgUnVs74P8C/27u+Wc5py3Rz/qS6Nzb5/A7+iowGxgcHXdU9B0YABjQroFzmQjsAq6LzqUjcCxwFnAw0At4DvifaP22wExgcvRz7QC8L1r2c+D7ace5Hvhzqf9OKv1V8gD81bpehMRxTdr0ecDiBtatAd5Mm97zzyOavgx4uYFtbwX+mjY9FNjewLofAF4FTgTaZCzb7x8ncBywFjg1mv448HzGOr8AbmngeA8B34g+DyIkkk4Z63QGNkX/iDs282ed/s/2/wFXpS1rA2wD+ud7/lmO80lgXfRP/OAo7otz+B0tAMZlmZ9L4nitiZguSh0XOCkVX5b13ktI+m2i6STwsZb+u6i2lxdVueZYkfZ5OXAEgKROkn4habmkLYSrxm6S2jawnyOBxY0c5420z9uADunFHylm9jfgDuBOYI2kuyV1zbZDSYcSimT+y8yej2b3B94raVPqRSjieU8Dcf2G8A8V4BOEu6ptGTG9TUhI1wCrJf2vpOMbOdem9AduT4tvI+Eqv28+59+ACcDvzGyXmb0L/IG9xVWN/Y6a+v01Jv07lCpielTS69F35yGgZ9pxlluWehAz+w/wNnB69PM9Ftiv2NAVlicO1xxHpn0+ilDkA6E4YzChKKMrocIVwj84CFeh6VYAxxQiIDP7qZmNAYYR7ii+mrmOpDaEf/p/N7NfZMRRa2bd0l6HmNnnGjjcX4CekmoICeQ3DcT0jJmdRSimmg/c08zTS8X42YwYO5rZv6NjNXT+jXZ/HdVBfQD4pKQ3JL0BfAQ4T1JPGv8dNbTs7ei9U9q8zCScGdf3onkjo+/OJ9n7vVkBHJXtoiHyYLT+p4DHzeydBtZzBeKJwzXHFyT1k3QYcBPw22h+F2A7sCladkvGdmuAo9OmnwTeI+mGqKKzi6T35huMpLik90o6iPBP6x2gPsuq3yEUIV2fMf9J4DhJn5J0UPSKSxqS7XjRle/jwA8J9TzPZompt6QLJXUG3gXeaiCmXE0B/o+kYdH+D5X00ehzY+ef+TPP9ClCMddgQtFiDSHxrCQkxcZ+R78EviVpUFRBP1JSDzNbB7xOSEZtJX2api8QuhB+Rpsk9WXfxP8SoZ7lNkmdJXWQdEra8l8DFxOSx6+aOI4rAE8crjl+Q7jqXhK9Uu0E/odQ0bkeeBF4OmO724GPRE8F/dTMthIqRC8gFEstBN7fjHi6Eq7m3yQUnW0AfpRlvcsI9QBvau+TVZdHcXwIuJRw9/QG8H1CeX9DfgN8EHgsVYQi6XJJc6PlbQh3YKsIxUqnA5+P1jtV0lv5nKCZPRHF9GhUlDMHODeH878XGBoVcf0xy64nAD83szfSX4RENaGJ39FPgN8RvgtbomN1jJZ9hvDPfwPhLujfTZziNwkPJWwG/pdQXJY69/ro+McCrxGS2sfTlq8EZhDuWJ7HFZ3MfCAn51zrJuk+YJWZ/d9Sx1INvAGgc65VkzQAGA+cUOJQqoYXVTnnWi1J3yIU2/3QzJaWOp5q4UVVzjnn8uJ3HM455/JSFXUcPXv2tAEDBpQ6DOeca1WmT5++3sz26/erKhLHgAEDSCaTTa/onHNuD0nLs833oirnnHN58cThcrJy5UrGjRvHoEGDOOaYY7j++uvZsWNHo9ts2rSJn//853umV61axUc+8pGCxHPrrbfyox/t38Zv4sSJPP744znvZ9myZfzmN1l7DNnHgAEDWL9+fV4xppx88snN2i7dpEmTmDcv/zGWHn74YUaOHMnIkSM5+eSTmTlz5p5ln/70pzn88MMZPnz4AcfnqosnDtckM2P8+PFcdNFFLFy4kFdffZW33nqLm2++udHtMhPHEUcckdc/9ZaQa+I4EP/+d1ONppv2y1/+kqFDh+a93cCBA6mtrWXWrFn813/9F1dfffWeZRMnTuTppzMb9zvXNE8crkl/+9vf6NChA1deeSUAbdu2ZfLkydx3331s27aNBx54gHHjxnHOOecwePBgvvnNbwJw4403snjxYmpqavjqV7/KsmXL9lzdPvDAA1x00UVccMEFDBw4kDvuuIOf/OQnnHDCCZx44ols3LgRgHvuuYd4PM6oUaO45JJL2LZtW/Yg0/z1r3/l1FNP5bjjjuPJJ58EQoI49dRTGT16NKNHj97zz/zGG2/k+eefp6amhsmTJ1NfX89XvvIVRowYwciRI/nZz362Z78/+9nPGD16NCNGjGD+/Pn7HXfu3LmMHTuWmpoaRo4cycKFCwE45JBDAPjGN75BTU0NNTU19O3bd8/P86GHHtqz3Wc/+1nq6/fv0uqMM84gmUxSX1/PxIkTGT58OCNGjGDy5MmN/ixOPvlkunfvDsCJJ57IypUr9yw77bTTOOyww5r8eTq3n1L3694SrzFjxphrvttvv91uuOGG/ebX1NTYzJkz7f7777f3vOc9tn79etu2bZsNGzbMEomELV261IYNG7Zn/fTp+++/34455hjbsmWLrV271rp27Wp33XWXmZndcMMNNnnyZDMzW79+/Z7tb775ZvvpT39qZma33HKL/fCHP9wvpgkTJtjZZ59t9fX19uqrr1rfvn1t+/bt9vbbb9v27dvNzOzVV1+11Hfi73//u334wx/es/3Pf/5zGz9+vO3cudPMzDZs2GBmZv37999z7DvvvNOuuuqq/Y597bXX2kMPPWRmZu+++65t27bNzMw6d+68z3qbNm2yESNGWDKZtHnz5tn5559vO3bsMDOzz33uc/bggw/ut+/TTz/dEomEJZNJ++AHP7hn/ptvvrnfug354Q9/uF/cmb8j59IBSWvJ8Tgk3acwlOWcBpZL0k8lLVIY6nJ02rJzFIbvXCTpxrT5hykMYbkweu9erPgd8PDDMGAAdv316N57w3QaM0MKPV+fddZZ9OjRg44dOzJ+/Hj++c9/Nrn797///XTp0oVevXpx6KGHcsEFFwAwYsQIli1bBsCcOXM49dRTGTFiBA8//DBz585tZI/Bxz72Mdq0acOgQYM4+uijmT9/Pjt37uQzn/kMI0aM4KMf/WiD9QV//etfueaaa2jXLjxwmH5FPn78eADGjBmzJ750J510Et/97nf5/ve/z/Lly+nYseN+65gZl19+OV/60pcYM2YM06ZNY/r06cTjcWpqapg2bRpLlixp8NyOPvpolixZwnXXXcfTTz9N1665Dbvx97//nXvvvZfvf//7Oa3vXGOKWVT1AGF4zoacSxg9bRBwNXAXhHGMCQPSnEsY9e0ySanC3RuBaWY2CJgWTbtiePhhuPpqWL6cYUBy69YwHSWPLVu2sGLFCo45JvSWnUogKZnT2Rx88N7OZ9u0abNnuk2bNuzaFcbsmThxInfccQezZ8/mlltu4Z13mh5qIVsskydPpnfv3sycOZNkMtlgxX56Mmwo3rZt2+6JL90nPvEJpk6dSseOHTn77LP529/+tt86t956K/369dtTTGVmTJgwgbq6Ourq6liwYAG33nprg+fWvXt3Zs6cyRlnnMGdd97JpEmTGlw3ZdasWUyaNIk//elP9OjRo8n1nWtK0RKHmT1H6E66IeOAX0V3RC8SRorrA4wFFpnZEjPbATwarZva5sHo84OE4SVdMdx8M0T1CWcSht/71bZtcPPN1NfX8+Uvf5mJEyfSqVMYq+fZZ59l48aNbN++nT/+8Y+ccsopdOnSha1btx5QGFu3bqVPnz7s3LmThzPueBry2GOPsXv3bhYvXsySJUsYPHgwmzdvpk+fPrRp04Zf//rXe+oRMmP80Ic+xJQpU/YkhlRdSy6WLFnC0UcfzRe/+EUuvPBCZs2atc/yJ598kmeffZaf/vSne+adeeaZPP7446xdu3bP8ZYvz/roPADr169n9+7dXHLJJXzrW99ixowZjcb02muvMX78eH79619z3HHH5XwuzjWmlJXjfdl3+MiV0byG5gP0NrPVANH74Q3tXNLVkpKSkuvWrSto4FXhtdf2fBTwBPAYMGj5co477jg6dOjAd7/73T3rvO997+NTn/oUNTU1XHLJJcRiMXr06MEpp5zC8OHD+epX9xuQLyff+ta3eO9738tZZ53F8cfnNvLq4MGDOf300zn33HOZMmUKHTp04POf/zwPPvggJ554Iq+++iqdO3cGYOTIkbRr145Ro0YxefJkJk2axFFHHcXIkSMZNWpUXk9c/fa3v2X48OHU1NQwf/58rrjiin2W//jHP2bVqlV7KsK/8Y1vMHToUL797W/zoQ99iJEjR3LWWWexevXqBo/x+uuvc8YZZ1BTU8PEiRP53ve+12hM//3f/82GDRv4/Oc/T01NDbFYbM+yyy67jJNOOokFCxbQr18/7r333pzP1VW3onZyGHV3/KSZ7feguKT/Bb5nZv+MpqcBXyOMVna2mU2K5n8KGGtm10naZGbd0vbxppk1Wc8Ri8XMW47nacAAyHbl278/ZJTvP/DAAySTSe64444WCc051zIkTTezWOb8Ut5xrGTfsav7EUZLa2g+wJqoOIvofW0LxFmdvvMd6g/utO+8Tp3gO98pTTzOubJRysQxFbgierrqRGBzVPyUAAZJGiipPWE4z6lp20yIPk8A/tTSQVeNyy9n6gV3s4z+7Ea82bU/3H03XH75fqumKrCdc9WhaJ0cSnoEOAPoKWklcAtwEICZTQGeAs4DFhHqXq+Mlu2SdC3wDNAWuM/MUs9g3gb8TtJVhLGHP1qs+B3ctfly3hhxOe3bQ7du8Nf9c4ZzrgpVxUBOXseRv507oXt3uPJK2LULHnkENm6ENt7XgHNVoxzrOFwZmz4d3n4bTj8dYjHYvBkWLy51VM65cuCJw2VVWxveTzsN4vHwOZEoXTzOufLhicNlVVsLQ4bA4YfD0KHQsaMnDudc4InD7WfXLvjnP0MxFUC7dnDCCeDVRM458MThsqirg61b9yYOCPUcM2aEpOKcq26eONx+UvUb6YkjHg9dV2UZhsI5V2U8cbj91NbCoEHQp8/eeakujryewznnicPto74enn9+37sNgOOOg65dvZ7DOeeJw2WYPRs2bdo/cbRpA2PG+B2Hc84Th8vwj3+E98zEAaG4auZMaGAMJOdclfDE4fZRWwtHHw1HHrn/sng8JI3Zs1s+Ludc+fDE4fbYvRueey773QZ4BblzLvDE4faYOzd0ZNhQ4hgwAHr08Apy56qdJw63R7b2G+mkcNfhdxzOVTdPHG6P2lo46qhwZ9GQeDzcmWzb1mJhOefKjCcOB4BZ4/UbKfF4aOtRV9ciYTnnypAnDgeErkTWrm06caQqyL2ew7nq5YnDAU3Xb6QccUR4eT2Hc9WrqIlD0jmSFkhaJOnGLMu7S3pC0ixJL0kanrbseklzJM2VdEPa/FslvS6pLnqdV8xzqBa1tSEhHHNM0+t6Bblz1a1oiUNSW+BO4FxgKHCZpKEZq90E1JnZSOAK4PZo2+HAZ4CxwCjgfEmD0rabbGY10eupYp1DtTALieP008OTU02Jx2HBAtiypfixOefKTzHvOMYCi8xsiZntAB4FxmWsMxSYBmBm84EBknoDQ4AXzWybme0CaoGLixhrVVu0CFavbrqYKiVVzzF9evFics6Vr2Imjr7AirTpldG8dDOB8QCSxgL9gX7AHOA0ST0kdQLOA9I7wbg2Kt66T1L3bAeXdLWkpKTkunXrCnNGFSrX+o0UryB3rroVM3FkK/SwjOnbgO6S6oDrgJeBXWb2CvB94FngaUKCSY09dxdwDFADrAZ+nO3gZna3mcXMLNarV68DO5MKV1sLvXvD4MG5rd+zZ2jr4fUczlWndkXc90r2vUvoB6xKX8HMtgBXAkgSsDR6YWb3AvdGy74b7Q8zW5PaXtI9wJNFO4MqkKrfOO203Oo3UuJxv+NwrloV844jAQySNFBSe+BSYGr6CpK6RcsAJgHPRckESYdH70cRirMeiabTxqXjYkKxlmumZctgxQo444z8tovHYelSWL++GFE558pZ0e44zGyXpGuBZ4C2wH1mNlfSNdHyKYRK8F9JqgfmAVel7eL3knoAO4EvmNmb0fwfSKohFHstAz5brHOoBo2Nv9GY9Arys88uaEjOuTJXzKIqokdln8qYNyXt8wvAoMztomWnNjD/U4WMsdrV1oY6i6GZD0o3YcyY8J5IeOJwrtp4y/Eq15z6DQjjjw8e7BXkzlUjTxxV7LXXQh1HvsVUKV5B7lx18sRRxfJtv5EpFoNVq8LLOVc9PHFUsdpa6N4dRoxo3vbxeHj3uw7nqosnjipWWwunngptmvktqKmBtm29nsO5auOJo0qtWhX6qGpuMRVAp04wbJjfcThXbTxxVKkDrd9IicfDHYdldibjnKtYnjiqVG1teKS2pubA9hOLwYYNsHx5QcJyzrUCnjiqVG0tvO99oY7iQKQqyL2ew7nq4YmjCq1ZE8YYP9BiKghPZLVv74nDuWriiaMKPfdceC9E4mjfHkaN8gpy56qJJ44qVFsLhxwCo0cXZn+xWOjscPfuwuzPOVfePHFUodpaOOUUOOigwuwvHg/jjy9cWJj9OefKmyeOKrN+PcyZU5hiqhSvIHeuunjiqDKFrN9IOf740BjQ6zmcqw6eOKpMbS107Lh3IKZCaNcu1Jf4HYdz1cETR5WprYWTTw5PQxVSLAYvvwy7dhV2v8658lPUxCHpHEkLJC2SdGOW5d0lPSFplqSXJA1PW3a9pDmS5kq6IW3+YZKelbQweu9ezHOoJG++CbNmFbaYKiUeh+3bYd68wu/bOVdeipY4JLUF7gTOBYYCl0nKHKD0JqDOzEYCVwC3R9sOBz4DjAVGAedLSg0xeyMwzcwGAdOiaZeD558PfUoVI3Gkir68uMq5ylfMO46xwCIzW2JmO4BHgXEZ6wwl/PPHzOYDAyT1BoYAL5rZNjPbBdQCF0fbjAMejD4/CFxUxHOoKLW1cPDBMHZs4fd97LFw6KFeQe5cNShm4ugLrEibXhnNSzcTGA8gaSzQH+gHzAFOk9RDUifgPODIaJveZrYaIHo/vGhnUGFqa+HEE6FDh8Lvu02bcNfhdxzOVb5iJg5lmZfZ+fZtQHdJdcB1wMvALjN7Bfg+8CzwNCHB5FXtKulqSUlJyXXr1uUbe8XZvDlUXhejmColFgt1KO++W7xjOOdKr5iJYyV77xIg3EnsMzq1mW0xsyvNrIZQx9ELWBotu9fMRpvZacBGINUueY2kPgDR+9psBzezu80sZmaxXr16FfC0Wqd//St0CVLMxBGPw86dIXk45ypXMRNHAhgkaaCk9sClwNT0FSR1i5YBTAKeM7Mt0bLDo/ejCMVZj0TrTQUmRJ8nAH8q4jlUjNra0MXIiScW7xipCnKv53CushUtcUSV2tcCzwCvAL8zs7mSrpF0TbTaEGCupPmEp6+uT9vF7yXNA/4MfMHM3ozm3wacJWkhcFY07ZpQWxsqxTt1Kt4xjjoKevXyeg7nKl27Yu7czJ4CnsqYNyXt8wvAoMztomWnNjB/A3BmAcOseG+9Fe4Cvv714h5HCncdfsfhXGXzluNV4N//hvp6OOOM4h8rHoe5c+Htt4t/LOdcaXjiqAK1taE/qZNPLv6xYrFQCf/yy8U/lnOuNDxxVIHa2vAPvXPn4h8r1cW6F1c5V7k8cVS4bdvgpZeK+xhuuve8B/r18wpy5yqZJ44K98ILoW1FSyUO8Apy5yqdJ44KV1sbugM55ZSWO2Y8Dq++Cps2tdwxnXMtxxNHhautDYMsde3acsdMNQScMaPljumcazmeOCrYO+/Af/7TssVU4F2sO1fpPHFUsP/8J3Q42NKJ47DD4OijPXE4V6k8cVSw2trQmvvUrG3wiyse9wpy5yqVJ44KVlsLo0ZBt24tf+x4HJYvB+/R3rnK44mjQu3YER7FbeliqhTvKde5yuWJo0IlErB9e+kSx+jRoZjM6zmcqzyeOCpUbW14L0X9BkCXLnD88X7H4Vwl8sRRoWprYcQI6NmzdDHE4+GOwzIHDHbOtWqeOCrQzp1hqNhSFVOlxGLwxhuwalXT6zrnWg9PHBVoxowwHkapE0eqp1yv53CusnjiqECp+o3TTittHKNGhXFAPHE4V1mKmjgknSNpgaRFkm7Msry7pCckzZL0kqThacu+JGmupDmSHpHUIZp/q6TXJdVFr/OKeQ6tUW0tDBkChx9e2jg6doThw72C3LlKU7TEIaktcCdwLjAUuEzS0IzVbgLqzGwkcAVwe7RtX+CLQMzMhgNtgUvTtptsZjXR6yncHrt2wfPPl76YKiXVgtwryJ2rHE0mDknnS2pOghkLLDKzJWa2A3gUGJexzlBgGoCZzQcGSOodLWsHdJTUDugEeBVrDurqYOvW8kkcsRhs3AhLl5Y6EudcoeSSEC4FFkr6gaQheey7L7AibXplNC/dTGA8gKSxQH+gn5m9DvwIeA1YDWw2s7+kbXdtVLx1n6Tu2Q4u6WpJSUnJdVXU70WqfqNcEodXkDtXeZpMHGb2SeAEYDFwv6QXon/KXZrYVNl2lzF9G9BdUh1wHfAysCtKBuOAgcARQGdJn4y2uQs4BqghJJUfNxD33WYWM7NYr169mgi1ctTWwqBB0KdPqSMJhg+Hgw/2eg7nKklORVBmtgX4PaG4qQ9wMTBD0nWNbLYSODJtuh8ZxU1mtsXMrjSzGkIdRy9gKfBBYKmZrTOzncAfgJOjbdaYWb2Z7QbuIRSJOaC+vrzqNwAOOghqavyOw7lKkksdxwWSngD+BhwEjDWzc4FRwFca2TQBDJI0UFJ7QpHX1Ix9d4uWAUwCnouS1GvAiZI6SRJwJvBKtE36tfTFwJwczrMqzJ4dhmstp8QBoZ5j+nTYvbvUkTjnCiGXO46PEp5iGmlmPzSztQBmtg34dEMbmdku4FrgGcI//d+Z2VxJ10i6JlptCDBX0nzC01fXR9v+B3gcmAHMjuK8O9rmB5JmS5oFvB/4Ul5nXMHKrX4jJR6Ht96CBQtKHYlzrhBkTTwnKWkgsNrM3ommOwK9zWxZ8cMrjFgsZskqKGQfPz48VbVkSakj2de8eTBsGDz4IFxxRamjcc7lStJ0M4tlzs/ljuMxIL2QoT6a58rI7t3w3HPld7cBMHgwdO7sFeTOVYpcEke7qB0GANHn9o2s70pg3jzYsKE8E0fbtjBmjFeQO1cpckkc6yRdmJqQNA5YX7yQXHOk6jfOOKOkYTQoFgvFaDt3ljoS59yByiVxXAPcJOk1SSuArwOfLW5YLl+1tXDUUTBgQKkjyS4eh3fegblzSx2Jc+5AtWtqBTNbTHg09hBCZfrW4ofl8mEWEsfZZ5c6koalj0FeU1PSUJxzB6jJxAEg6cPAMKBDaFYBZvbfRYzL5WHBAli7tjzrN1KOOQa6dQv1HJMmlToa59yByKUB4BTg44QuQURo19G/yHG5PJRr+410Urjr8CernGv9cqnjONnMrgDeNLNvAiexb1cirsRqa+GII8JVfTmLx2HWrFDX4ZxrvXJJHKk/822SjgB2EjofdGXADP7xj3C3oWzdSpaReDyMFzJzZqkjcc4diFwSx58ldQN+SOgCZBnwSBFjcnlYtAhWry7vYqqU9Apy51zr1WjleDSA0zQz2wT8XtKTQAcz29wSwbmmtYb6jZR+/aB3b28I6Fxr1+gdR9R1+Y/Tpt/1pFFeamvDP+PBg0sdSdO8gty5ypDL47h/kXQJ8AdrqkdE16i1a+HLX4bt2wu3z2nT4Kyzyr9+IyUeh6eego98pNSR5Of882HixFJHkd2OHfDFL8J678/BZXHzzXDCCYXdZy6J4/8DOhNG5nuH8EiumVnXwoZS+f74R3joITj++NB/UyEceSR8usHO7cvPxRfD1Kkwf36pI8nd6tXw0kvlmzhefBF+8Qs4+mjo2LHU0bhy8/bbhd9nLi3Hmxoi1uUomYTu3UOHhK3lDqHQRo4Mgzq1Jj/5SbhTXLMmFAuWm1TR3wsvwOGHlzYWVx2aTBySTss238yeK3w4lS2RCGX81Zo0Wqv0p8E+/OHSxpJNIhH6KfOk4VpKLkVVX0373IEwxvd04ANFiahCbd8Oc+bA175W6khcvkaPDsm+XBNHMhnqjpxrKbkUVV2QPi3pSOAHRYuoQs2cGRq/xfYbS8uVu0MOgSFDyvMx4jffDG15rrqq1JG4apJLA8BMK4Hhuawo6RxJCyQtknRjluXdJT0haZaklyQNT1v2JUlzJc2R9IikDtH8wyQ9K2lh9N69GefQ4lL/dPzKsHWKx8PvsNyeK0zVb/j3yrWkXDo5/Jmkn0avO4DngSY7jZDUFrgTOBcYClwmaWjGajcBdWY2ErgCuD3ati/wRSBmZsOBtsCl0TY3EholDgKmRdNlL5kMFat9+5Y6EtccsVh4nHrlylJHsq9U4hgzprRxuOqSyx1HklCnMR14Afi6mX0yh+3GAovMbEk03OyjwLiMdYYS/vljZvOBAZJSz620AzpKagd0AlZF88cBD0afHwQuyiGWkkskwlWhV4y3Tqkr+nIrrkokYNCg0GW9cy0ll8TxOPCQmT1oZg8DL0rqlMN2fYEVadMro3npZgLjASSNJXTX3s/MXgd+BLwGrAY2m9lfom16m9lqgOg967Mkkq6WlJSUXLduXQ7hFs/WraHdgtdvtF6jRkG7duXX6j2Z9O+Va3m5JI5pQHqzoo7AX3PYLtu1dWYJ8W1Ad0l1hPE+XiY0NOxOuLMYCBwBdJaUy13O3gOZ3W1mMTOL9erVK59NC27GjFA27uXQrVeHDjBiRHndcaxZAytW+PfKtbxcEkcHM3srNRF9zuWOYyX7jtvRj73FTal9bTGzK82shlDH0QtYCnwQWGpm68xsJ/AH4ORoszWS+gBE72tziKWkUlepfmXYusXj4XdZLhXkXjHuSiWXxPG2pNGpCUljgFx6W0oAgyQNlNSeULk9NX0FSd2iZQCTgOfMbAuhiOpESZ0Uxqo9E3glWm8qMCH6PAH4Uw6xlJQ30KoMsRhs2gSLF5c6kiCRgDZtCt8PkXNNyaUB4A3AY5JSdwt9CEPJNsrMdkm6FniG8FTUfWY2V9I10fIpwBDgV5LqgXnAVdGy/0h6nDD+xy5CEdbd0a5vA34n6SpCgvloLidaSt5AqzKkfofJJBx7bGljgZA4hg6Fzp1LHYmrNrk0AExIOh4YTKi3mB8VHzXJzJ4CnsqYNyXt8wvAoAa2vQW4Jcv8DYQ7kFZh48ZwhTppUqkjcQdq2LBQ15FIwKWXNr1+MZmFBHbeeaWNw1WnXNpxfAHobGZzzGw2cIikzxc/tMrg5dCV46CDoKamPJ6sWrEitCvx75UrhVzqOD4TjQAIgJm9CXymaBFVGG+gVVlisdC7b319aePwBy5cKeWSONpEFdTAnhbh7RtZ36XxBlqVJR4P4xuUejyRRCLcAY0aVdo4XHXKJXE8Q6iMPlPSB4BHgP9X3LAqhzfQqizpXayXUjIZ2pUcfHBp43DVKZfE8XVCI8DPAV8AZrFvg0DXgDfeCH0beTl05Rg8OPSWW8qGgKmKcf9euVJpMnGY2W7gRWAJEGPfNhWuEV4OXXnatg31VaW841i8OLQn8cThSqXBx3ElHUdotHcZsAH4LYCZvb9lQmv9Ug20Ro9uel3XesRicMcdsGMHtC9BbV/qbscvSFypNHbHMZ9wd3GBmb3PzH4GlPhZktYlmfQGWpUoHod334W5c0tz/EQitCcZNqw0x3euscRxCfAG8HdJ90g6k+wdF7oszPaOMe4qS+p3Wqp6jmQydDPSLpd+H5wrggYTh5k9YWYfB44H/gF8Cegt6S5JH2qh+Fqt116Ddeu8HLoSHX00dO9emnqO+vrQ27J/r1wp5VI5/raZPWxm5xN6uK2jlYy6V0peMV65pPB7LcUdx/z5oR2Jf69cKeU15riZbTSzX5jZB4oVUKXwBlqVLR6H2bNhey79RBeQj13vykFeicPlzhtoVbZYLBQbzZzZssdNJqFLFzjuuJY9rnPpPHEUwe7d3kCr0pVqDPJEIrQjaeN/ua6E/OtXBIsXw+bNXg5dyfr2hfe8p2UryHfsgLo6vyBxpeeJowi8HLrylaKCfM6ckDz8gsSVmieOIkgmQwOtoUNLHYkrpng8POW0dWvLHM8vSFy58MRRBIlEaKB10EGljsQVUywWGnrOmNEyx0smoUcPGDCgZY7nXEOKmjgknSNpgaRFkvZr+yGpu6QnJM2S9JKk4dH8wZLq0l5bJN0QLbtV0utpy8pq8Mxdu7yBVrVo6S7WUz0RyPtvcCVWtE4LogGf7gTOAlYCCUlTzWxe2mo3AXVmdnE0rvmdwJlmtgCoSdvP68ATadtNNrMfFSv2AzF/Pmzb5uXQ1eDww+Goo1qmnmP79lDHcf75xT+Wc00p5h3HWGCRmS0xsx3Ao8C4jHWGEsb6wMzmAwMk9c5Y50xgsZktL2KsBePl0NUlHm+ZxFFXF9qN+PfKlYNiJo6+wIq06ZXRvHQzgfEAksYC/QndmqS7lDDqYLpro+Kt+yR1z3ZwSVdLSkpKrlu3rrnnkDdvoFVdYjFYsgQ2bizucbwLG1dOipk4spXEWsb0bUB3SXXAdcDLwK49O5DaAxcCj6VtcxdwDKEoazXw42wHN7O7zSxmZrFevXo18xTy5w20qkvqDqDY9RyJBPTpE9qPOFdqxfz3thI4Mm26H7AqfQUz22JmV5pZDXAF0AtYmrbKucAMM1uTts0aM6uPRia8h1AkVhZ27AhdUPhVYfUYMya8t0Ti8GIqVy6KmTgSwCBJA6M7h0uBqekrSOoWLQOYBDxnZlvSVrmMjGIqSX3SJi8G5hQ88maaPTskD/8Drx7dusGgQcWt59iyBRYs8AsSVz6K9lSVme2SdC3wDNAWuM/M5kq6Jlo+BRgC/EpSPTAPuCq1vaROhCeyPpux6x9IqiEUey3LsrxkvBy6OsXj8Nxzxdv/jBmhvYhfkLhyUdQxxMzsKeCpjHlT0j6/AAxqYNttQI8s8z9V4DALJpEIDbQGDix1JK4lxWLwm9/AG2+E/qsKzS9IXLnxKtwC8gZa1anYFeSJRGgt3rNncfbvXL48cRTItm0wd65fFVajE04IT9EVq54jmfTvlSsvnjgKxBtoVa/OnUOHlsW449iwIbQT8e+VKyeeOArEy6GrW6qLdctsqXSA/HvlypEnjgLxBlrVLR6HdevgtdcKu99U4ki1F3GuHHjiKBAvh65uxaogTyRg8GA49NDC7te5A+GJowBSDbS8HLp6jRwZxl8pdAW5X5C4cuSJowBSDbT8D7x6HXxwSB6FvONYvRpef90vSFz58cRRAKmrTE8c1S0WC4lj9+7C7M8rxl258sRRAIkE9O8PLdgJrytD8Ths3gyLFxdmf4lEaB9ywgmF2Z9zheKJowCSSS9OcHvvDApVz5FMwrBh0KlTYfbnXKF44jhA69fD0qWeOFz4J9+hQ2HqOcy8K3VXvjxxHKDp08O7l0O7du1CsVIh7jiWLw8XJf69cuXIE8cBSv2T8AZaDsIdwowZsGtX0+s2JnXX4nccrhx54jhAyWQYX9wbaDkI/+i3bYP58w9sP4kEtG8PI0YUJi7nCskTxwHycmiXrlAV5MlkaBdy8MEHHpNzheaJ4wCsWhVeXg7tUo47Drp0ObAK8t27/Uk9V96KmjgknSNpgaRFkm7Msry7pCckzZL0kqTh0fzBkurSXlsk3RAtO0zSs5IWRu/di3kOjfFyaJepTZtQ33UgdxyLFoVubPyCxJWroiUOSW2BO4FzgaHAZZKGZqx2E1BnZiOBK4DbAcxsgZnVmFkNMAbYBjwRbXMjMM3MBgHToumSSDXQqqkpVQSuHMXjMHMm7NjRvO1TSccvSFy5KuYdx1hgkZktMbMdwKPAuIx1hhL++WNm84EBknpnrHMmsNjMlkfT44AHo88PAhcVIfacpBpode5cqghcOYrFQtKYPbt52ycS0LEjDBlS2LicK5RiJo6+wIq06ZXRvHQzgfEAksYC/YF+GetcCjySNt3bzFYDRO+HZzu4pKslJSUl161b1+yTaIg30HINOdAu1pNJGD06tAtxrhwVM3Eoy7zM8dFuA7pLqgOuA14G9jwBL6k9cCHwWL4HN7O7zSxmZrFeRehEavnyMKynl0O7TAMGQI8ezavn2LUrtAPx75UrZ8W8plkJHJk23Q9Ylb6CmW0BrgSQJGBp9Eo5F5hhZmvS5q2R1MfMVkvqA6wtRvBN8XJo1xBp71Cy+XrlFdi+3b9XrrwV844jAQySNDC6c7gUmJq+gqRu0TKAScBzUTJJuYx9i6mI9jEh+jwB+FPBI89BMhkG7vEGWi6beBzmzg2NAfPhFySuNSha4jCzXcC1wDPAK8DvzGyupGskXROtNgSYK2k+4e7i+tT2kjoBZwF/yNj1bcBZkhZGy28r1jk0JpGAUaO8gZbLLhaD+nqoq8tvu2QSunaFY48tSljOFURRq9/M7CngqYx5U9I+vwAMamDbbUCPLPM3EJ60Kpndu0Pnhp/4RCmjcOUsvYL85JNz3y6RCEmnjTfNdWXMv57NsHBhaKDlxQmuIUccAX365FfP8e67of2HV4y7cueJoxl8qFiXi3g8v0dyZ8+GnTv9gsSVP08czZBMhgZaQzPbwTuXJhaDBQvC3Wku/ILEtRaeOJohkQgD9ngDLdeYeDw0FJ0xI7f1k0no2TOMX+9cOfPEkaddu+Dll704wTUt3y7WUxXjytZ01rky4okjT/PmeQMtl5uePUMr8lzqObZtC+0+/HvlWgNPHHlK/RPwcmiXi3g8tzuOl18Oj3l74nCtgSeOPCUSoYHWoKytT5zbVywGS5fC+vWNr+cXJK418cSRp2QyDNTjDbRcLlJ3ENOnN75eIgF9+4a2H86VO//3l4dUAy0vTnC5Gj06vDdVXJWqGHeuNfDEkYdZs0IDLf8Dd7k69FAYPLjxCvLNm+HVV/2CxLUenjjy4GOMu+Zoqov1VDGWX5C41sITRx4SiTBAjzfQcvmIx2HVqvDKxivGXWvjiSMPyWT4J+ANtFw+UgmhoeKqRAIGDgwXJc61Bp44cvT2295AyzXPCSdA27YNJ47UBYlzrYUnjhzV1YUGWl6c4PLVqRMMG5a9nmPdOli2zBOHa108ceTIey51ByJVQW6273yvGHetkSeOHCWTYXCeI44odSSuNYrHYcMGWL583/mJRKgzS7X3cK41KGrikHSOpAWSFkm6Mcvy7pKekDRL0kuShqct6ybpcUnzJb0i6aRo/q2SXpdUF73OK+Y5pCQSXpzgmq+hnnITidDOo2vXlo/JueYqWuKQ1Ba4EzgXGApcJilz6KObgDozGwlcAdyetux24GkzOx4YBbyStmyymdVEr33GNC+GTZtCAy0vTnDNNWIEtG+/fwW5V4y71qiYdxxjgUVmtsTMdgCPAuMy1hkKTAMws/nAAEm9JXUFTgPujZbtMLNNRYy1UamBePwP3DXXwQfDyJH73nG8/jqsXu0XJK71KWbi6AusSJteGc1LNxMYDyBpLNAf6AccDawD7pf0sqRfSuqctt21UfHWfZK6Zzu4pKslJSUl161bd0AnkvpjHzPmgHbjqlw8HirDd+8O094TgWutipk4sjWTy3imhNuA7pLqgOuAl4FdQDtgNHCXmZ0AvA2k6kjuAo4BaoDVwI+zHdzM7jazmJnFevXqdUAnkkyGBlo9ex7QblyVi8XC+OMLF4bpRCK07xg1qrRxOZevYiaOlcCRadP9gH06XTCzLWZ2pZnVEOo4egFLo21Xmtl/olUfJyQSzGyNmdWb2W7gHkKRWFF5z6WuEFJ3Fqk7jWQShg8P7Tyca02KmTgSwCBJAyW1By4FpqavED051T6anAQ8FyWTN4AVkgZHy84E5kXbpI9YcDEwp4jnwLp14RFKL05wB2rIkJAkUu05/Ek911q1K9aOzWyXpGuBZ4C2wH1mNlfSNdHyKcAQ4FeS6gmJ4aq0XVwHPBwlliXAldH8H0iqIRR7LQM+W6xzAC+HdoXTrl3ofiSRCKMCbtzod7KudSpa4gCIHpV9KmPelLTPLwBZB2E1szpgvz8rM/tUYaNsXDLpDbRc4cTj8ItfwIsv7p12rrXxluNN8AZarpBiMdi+HX71q9CuY/jwprdxrtx44mhEqhzaixNcoaTuMJ55BmpqQvJwrrXxxNGIVavgjTe8OMEVzrHH7r179QsS11p54miE94jrCq1Nm73fJ78gca2VJ45GJJOhgVZNTakjcZUklTj8gsS1VkV9qqq1GzgQJkzwBlqusD7zmVC3MTSzy0/nWglZ5sgyFSgWi1myoXE7nXPOZSVpupntd2/sRVXOOefy4onDOedcXjxxOOecy4snDuecc3nxxOGccy4vnjicc87lxROHc865vHjicM45l5eqaAAoaR2wvNRxRHoC60sdRBM8xgNX7vFB+cdY7vFB5cfY38x6Zc6sisRRTiQls7XELCce44Er9/ig/GMs9/igemP0oirnnHN58cThnHMuL544Wt7dpQ4gBx7jgSv3+KD8Yyz3+KBKY/Q6Duecc3nxOw7nnHN58cThnHMuL544ikjSfZLWSpqTNu8wSc9KWhi9dy9hfEdK+rukVyTNlXR9GcbYQdJLkmZGMX6z3GKM4mkr6WVJT5ZpfMskzZZUJylZpjF2k/S4pPnRd/KkcolR0uDoZ5d6bZF0Q7nElxbnl6K/kzmSHon+fgoeoyeO4noAOCdj3o3ANDMbBEyLpktlF/BlMxsCnAh8QdLQMovxXeADZjYKqAHOkXQi5RUjwPXAK2nT5RYfwPvNrCbtmf5yi/F24GkzOx4YRfh5lkWMZrYg+tnVAGOAbcAT5RIfgKS+wBeBmJkNB9oClxYlRjPzVxFfwABgTtr0AqBP9LkPsKDUMabF9ifgrHKNEegEzADeW04xAv2iP8gPAE+W4+8ZWAb0zJhXNjECXYGlRA/slGOMaTF9CPhXucUH9AVWAIcB7YAno1gLHqPfcbS83ma2GiB6P7zE8QAgaQBwAvAfyizGqBioDlgLPGtm5Rbj/wBfA3anzSun+AAM+Iuk6ZKujuaVU4xHA+uA+6Miv19K6lxmMaZcCjwSfS6b+MzsdeBHwGvAamCzmf2lGDF64nBIOgT4PXCDmW0pdTyZzKzeQhFBP2CspOElDmkPSecDa81seqljacIpZjYaOJdQJHlaqQPK0A4YDdxlZicAb1P6orP9SGoPXAg8VupYMkV1F+OAgcARQGdJnyzGsTxxtLw1kvoARO9rSxmMpIMISeNhM/tDNLusYkwxs03APwj1RuUS4ynAhZKWAY8CH5D0UBnFB4CZrYre1xLK5sdSXjGuBFZGd5MAjxMSSTnFCCHxzjCzNdF0OcX3QWCpma0zs53AH4CTixGjJ46WNxWYEH2eQKhXKAlJAu4FXjGzn6QtKqcYe0nqFn3uSPjjmE+ZxGhm/8fM+pnZAEIRxt/M7JPlEh+ApM6SuqQ+E8q951BGMZrZG8AKSYOjWWcC8yijGCOXsbeYCsorvteAEyV1iv62zyQ8YFD4GEtd0VTJL8IXbDWwk3BFdRXQg1CRujB6P6yE8b2PUPY9C6iLXueVWYwjgZejGOcA34jml02MabGewd7K8bKJj1B/MDN6zQVuLrcYo3hqgGT0u/4j0L2cYiQ8nLEBODRtXtnEF8XzTcKF1Rzg18DBxYjRuxxxzjmXFy+qcs45lxdPHM455/LiicM551xePHE455zLiycO55xzefHE4VwDJA1I79k4x20mSjoih3XuaGZM10i6ojnbOlco7UodgHMVZiLhGfpVxdi5mU0pxn6dy4ffcTjXuHaSHpQ0KxorohOApG9ISkTjHtyt4CNADHg4GrOho6S4pH8rjCfyUqoFN3CEpKejMRJ+kO3Akm6TNC869o+iebdK+oqkIzLGh6iX1D9qaf/7KLaEpFNa5KfkqoonDucaNxi428xGAluAz0fz7zCzuIVxDzoC55vZ44SWz5db6JSxHvgtcL2F8UQ+CGyPtq8BPg6MAD4u6cj0g0o6DLgYGBYd+9vpy81sle0dH+Ie4PdmtpwwpsVkM4sDlwC/LNhPwrmIJw7nGrfCzP4VfX6I0E0LwPsl/UfSbMI4HMOybDsYWG1mCQAz22Jmu6Jl08xss5m9Q+iTqX/GtluAd4BfShpPGDhoP9EdxSTg09GsDwJ3RN3QTwW6pt3lOFcQXsfhXOMy++QxSR2AnxNGWlsh6VagQ5ZtlWX7lHfTPteT8bdoZrskjSV0VHcpcC0hQe3deejp9F7gQjN7K5rdBjjJzLbjXJH4HYdzjTtK0knR58uAf7I3SayPxjL5SNr6W4HUFf58Ql1GHEBSF0k5XaxF+z3UzJ4CbiAUbaUvPwj4HfB1M3s1bdFfCEkmtd4+2zlXCJ44nGvcK8AESbMIQ3LeZWFckHuA2YReXBNp6z8ATImKitoS6jF+Jmkm8CzZ70yy6QI8GR23FvhSxvKTgTjwzbQK8iOIxpyOKtTnAdfkd7rONc17x3XOOZcXv+NwzjmXF08czjnn8uKJwznnXF48cTjnnMuLJw7nnHN58cThnHMuL544nHPO5eX/B2r03UyaPfF+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx2=df2[df2[\"Accuracy\"]==df2.max()[\"Accuracy\"]]\n",
    "_ = plt.plot(df2[\"batch size\"],df2['Accuracy'],'b')\n",
    "_ = plt.plot(idx2.iloc[0,2],idx2.iloc[0,1],'ro')\n",
    "_ = plt.annotate(f'Optimal batch size is  {idx2.iloc[0,2]:.0f}',(idx2.iloc[0,2],idx2.iloc[0,1]))\n",
    "_ = plt.xlabel('batch size')\n",
    "_ = plt.ylabel('Accuracy')\n",
    "_ = plt.title('batch size v.s. Test Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>The optimal batch size is 21</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs training size plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0747 - accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9668 - accuracy: 0.3750\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8708 - accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7955 - accuracy: 0.5417\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.7301 - accuracy: 0.5417\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.5833\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6036 - accuracy: 0.6250\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5513 - accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7083\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.4678 - accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.9167\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4041 - accuracy: 0.9583\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.3765 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.3547 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.3191 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.2724 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2576 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBF19CD160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.4144 - accuracy: 0.9259\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.1232 - accuracy: 0.2162\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0025 - accuracy: 0.8108\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.9387 - accuracy: 0.7568\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8600 - accuracy: 0.7297\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.7584 - accuracy: 0.7838\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.6379 - accuracy: 0.8108\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.5034 - accuracy: 0.8649\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.9459\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9730\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 989us/step - loss: 0.1753 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.1021 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 991us/step - loss: 0.0570 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 501us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 489us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 499us/step - loss: 6.6063e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 3.7457e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3523e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBEDFDDC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 501us/step - loss: 0.3051 - accuracy: 0.9259\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 990us/step - loss: 1.2066 - accuracy: 0.2449\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 504us/step - loss: 1.0151 - accuracy: 0.2857\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.9176 - accuracy: 0.5102\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 994us/step - loss: 0.8404 - accuracy: 0.5918\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.7925 - accuracy: 0.6122\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.5918\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.5918\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.6122\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.6939\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.5224 - accuracy: 0.8571\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 994us/step - loss: 0.4809 - accuracy: 0.8980\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.9184\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.4003 - accuracy: 0.9184\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.3665 - accuracy: 0.9184\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.3274 - accuracy: 0.9592\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.9796\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.2550 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 993us/step - loss: 0.2227 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE95C7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 510us/step - loss: 0.2652 - accuracy: 0.9259\n",
      "Epoch 1/20\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2203 - accuracy: 0.2812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2531 - accuracy: 0.3226\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 496us/step - loss: 1.0336 - accuracy: 0.6452\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.8671 - accuracy: 0.7581\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.7182 - accuracy: 0.8710\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.5867 - accuracy: 0.8871\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 498us/step - loss: 0.4705 - accuracy: 0.9032\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.3685 - accuracy: 0.9194\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 496us/step - loss: 0.2863 - accuracy: 0.9516\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.2021 - accuracy: 0.9677\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9677\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0968 - accuracy: 0.9677\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9677\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0494 - accuracy: 0.9839\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 495us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE94F21F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0983 - accuracy: 0.9630\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1.1795 - accuracy: 0.1622\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.0292 - accuracy: 0.5135\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.9145 - accuracy: 0.7162\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.7972 - accuracy: 0.8243\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.6680 - accuracy: 0.8514\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 671us/step - loss: 0.5185 - accuracy: 0.9324\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 671us/step - loss: 0.3707 - accuracy: 0.9459\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.2533 - accuracy: 0.9459\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.1622 - accuracy: 0.9459\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 333us/step - loss: 0.1092 - accuracy: 0.9459\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0695 - accuracy: 0.9865\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 333us/step - loss: 0.0489 - accuracy: 0.9865\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBF0670040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0643 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 994us/step - loss: 1.0157 - accuracy: 0.4535\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 659us/step - loss: 0.8306 - accuracy: 0.6279\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.6744\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.5456 - accuracy: 0.8953\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.9767\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.2312 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 671us/step - loss: 0.1137 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.0426 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 656us/step - loss: 8.3552e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 333us/step - loss: 4.2872e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 668us/step - loss: 2.3393e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1.6527e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 1.1788e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8.8121e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7.3822e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 679us/step - loss: 6.2047e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5.5548e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE83ED700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9630\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 742us/step - loss: 1.1069 - accuracy: 0.2424\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.9265 - accuracy: 0.8485\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7590 - accuracy: 0.9192\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.9091\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4104 - accuracy: 0.9394\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.2287 - accuracy: 0.9798\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.1041 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0180 - accuracy: 0.9899\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 3.0534e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 581us/step - loss: 4.7445e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 9.6906e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 508us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE95C7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 747us/step - loss: 1.0473 - accuracy: 0.5045\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 743us/step - loss: 0.8443 - accuracy: 0.9099\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.5306 - accuracy: 0.9459\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.2399 - accuracy: 0.9730\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0972 - accuracy: 0.9820\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0480 - accuracy: 0.9910\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 744us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 504us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 9.0127e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 7.5414e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 499us/step - loss: 5.4204e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 743us/step - loss: 3.4886e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 743us/step - loss: 2.7366e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 2.5114e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 743us/step - loss: 2.1242e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 1.9292e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 1.8024e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBEE00AAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 762us/step - loss: 1.0267 - accuracy: 0.4839\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.8499 - accuracy: 0.6694\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6251 - accuracy: 0.6855\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.4380 - accuracy: 0.7016\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.3214 - accuracy: 0.9113\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.2346 - accuracy: 0.9758\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1434 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 988us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 760us/step - loss: 8.8589e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 998us/step - loss: 6.5574e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 4.3903e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 3.3980e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 2.9036e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 2.5341e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 2.1748e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 2.0328e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE83529D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 571us/step - loss: 0.0807 - accuracy: 0.9630\n"
     ]
    }
   ],
   "source": [
    "sizes=[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "accuracy_train_set=[]\n",
    "predictions=0\n",
    "for i in sizes:\n",
    "    if(i!=1):\n",
    "        Xtrain,cv_X,Ytrain,cv_Y=train_test_split(X_train,Y_train,train_size=i)\n",
    "    else:\n",
    "        Xtrain=X_train\n",
    "        Ytrain=Y_train\n",
    "    model=tf.keras.models.Sequential([tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                         tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(3,activation=tf.nn.softmax)])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.015),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(Xtrain,Ytrain,epochs=20,batch_size=32)\n",
    "    accuracy_train_set.append(model.evaluate(X_test,Y_test,batch_size=32))\n",
    "df3=pd.DataFrame(accuracy_train_set,columns=['loss','Accuracy'])#storing all the accuries in the Dataframe\n",
    "df3[\"training set ratio\"]=[i for i in sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>training set ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.414361</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.305082</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.265182</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.098284</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.126555</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.080659</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064317</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.109858</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  Accuracy  training set ratio\n",
       "0  0.414361  0.925926                 0.2\n",
       "1  0.305082  0.925926                 0.3\n",
       "2  0.265182  0.925926                 0.4\n",
       "3  0.098284  0.962963                 0.5\n",
       "5  0.126555  0.962963                 0.7\n",
       "8  0.080659  0.962963                 1.0\n",
       "4  0.064317  0.981481                 0.6\n",
       "7  0.109858  0.981481                 0.9\n",
       "6  0.001691  1.000000                 0.8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.sort_values(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx3=df3[df3[\"Accuracy\"]==df3.max()[\"Accuracy\"]]\n",
    "_ = plt.plot(df3[\"training set ratio\"],df3['Accuracy'],'b')\n",
    "_ = plt.plot(idx3.iloc[0,2],idx3.iloc[0,1],'ro')\n",
    "_ = plt.annotate(f'Optimal  train set percentage is  {idx3.iloc[0,2]:.3f}',(idx3.iloc[0,2],idx3.iloc[0,1]))\n",
    "_ = plt.xlabel('train set percentage')\n",
    "_ = plt.ylabel('Accuracy')\n",
    "_ = plt.title('train set percentage v.s. Test Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs features percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.0488 - accuracy: 0.4274\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 990us/step - loss: 0.9346 - accuracy: 0.5242\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.8550 - accuracy: 0.6290\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8170 - accuracy: 0.6210\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.8266 - accuracy: 0.5565\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 760us/step - loss: 0.7874 - accuracy: 0.6613\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.8062 - accuracy: 0.5806\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.7806 - accuracy: 0.6048\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.7720 - accuracy: 0.6048\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.7557 - accuracy: 0.6290\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.7577 - accuracy: 0.6694\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.7401 - accuracy: 0.6694\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.7340 - accuracy: 0.6774\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.7134 - accuracy: 0.6694\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.7183 - accuracy: 0.6371\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.7077 - accuracy: 0.6613\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 507us/step - loss: 0.7094 - accuracy: 0.6694\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.6844 - accuracy: 0.6855\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 507us/step - loss: 0.6867 - accuracy: 0.6774\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.6716 - accuracy: 0.6935\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBECBD55E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 487us/step - loss: 0.7112 - accuracy: 0.7407\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 474us/step - loss: 1.1194 - accuracy: 0.3145\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.9982 - accuracy: 0.5887\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.8624 - accuracy: 0.6532\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.7205 - accuracy: 0.7339\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.6058 - accuracy: 0.7581\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.5509 - accuracy: 0.7419\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7258\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.5154 - accuracy: 0.7339\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.5047 - accuracy: 0.7661\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7823\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.4797 - accuracy: 0.7903\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.4714 - accuracy: 0.7742\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.4624 - accuracy: 0.7903\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 757us/step - loss: 0.4536 - accuracy: 0.8065\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.4517 - accuracy: 0.7903\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.4500 - accuracy: 0.8145\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 739us/step - loss: 0.4396 - accuracy: 0.8065\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4395 - accuracy: 0.8065\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.4340 - accuracy: 0.7742\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.4295 - accuracy: 0.8226\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBF1A199D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.5266 - accuracy: 0.6852\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 762us/step - loss: 1.0043 - accuracy: 0.5161\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.6653 - accuracy: 0.8145\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.4330 - accuracy: 0.9194\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.2467 - accuracy: 0.9355\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1556 - accuracy: 0.9355\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.1264 - accuracy: 0.9516\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 755us/step - loss: 0.1125 - accuracy: 0.9516\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.1031 - accuracy: 0.9516\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0884 - accuracy: 0.9677\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 745us/step - loss: 0.0730 - accuracy: 0.9758\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0833 - accuracy: 0.9758\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0663 - accuracy: 0.9758\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0663 - accuracy: 0.9919\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.0587 - accuracy: 0.9919\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.0602 - accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0587 - accuracy: 0.9758\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0499 - accuracy: 0.9919\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0477 - accuracy: 0.9919\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0451 - accuracy: 0.9919\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0410 - accuracy: 0.9919\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE6D2CEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2356 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.9259\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 995us/step - loss: 1.1035 - accuracy: 0.3065\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9513 - accuracy: 0.4919\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.7855 - accuracy: 0.5806\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6030 - accuracy: 0.7419\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.8387\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.9274\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.9597\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9597\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.1466 - accuracy: 0.9677\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.1027 - accuracy: 0.9677\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0788 - accuracy: 0.9597\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0678 - accuracy: 0.9597\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.0567 - accuracy: 0.9758\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0519 - accuracy: 0.9758\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0456 - accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 757us/step - loss: 0.0354 - accuracy: 0.9919\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0286 - accuracy: 0.9919\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0226 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE95C7F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4844 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.9074\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9549 - accuracy: 0.6210\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 989us/step - loss: 0.5880 - accuracy: 0.8790\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.9274\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9435\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 991us/step - loss: 0.1141 - accuracy: 0.9677\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 990us/step - loss: 0.0788 - accuracy: 0.9839\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.0750 - accuracy: 0.9758\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 748us/step - loss: 0.0736 - accuracy: 0.9758\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 745us/step - loss: 0.0631 - accuracy: 0.9839\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.0651 - accuracy: 0.9839\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 991us/step - loss: 0.0524 - accuracy: 0.9839\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9839\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0469 - accuracy: 0.9839\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 992us/step - loss: 0.0405 - accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0323 - accuracy: 0.9919\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0300 - accuracy: 0.9839\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 739us/step - loss: 0.0356 - accuracy: 0.9839\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0403 - accuracy: 0.9839\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0298 - accuracy: 0.9919\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBECBD5CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 496us/step - loss: 0.2333 - accuracy: 0.9630\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0176 - accuracy: 0.5887\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 988us/step - loss: 0.6731 - accuracy: 0.9032\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 740us/step - loss: 0.3690 - accuracy: 0.9355\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 984us/step - loss: 0.1983 - accuracy: 0.9435\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.1228 - accuracy: 0.9435\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.0861 - accuracy: 0.9758\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0520 - accuracy: 0.9839\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.0373 - accuracy: 0.9919\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0226 - accuracy: 0.9919\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 754us/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 759us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 491us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 741us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 757us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE6AC3670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 517us/step - loss: 0.2355 - accuracy: 0.9630\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 744us/step - loss: 1.0149 - accuracy: 0.4194\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 739us/step - loss: 0.7732 - accuracy: 0.5726\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 753us/step - loss: 0.4877 - accuracy: 0.9113\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 744us/step - loss: 0.2223 - accuracy: 0.9758\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 746us/step - loss: 0.0684 - accuracy: 0.9919\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 742us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 760us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 743us/step - loss: 6.9474e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 493us/step - loss: 4.1324e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 499us/step - loss: 2.7034e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 2.4329e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 743us/step - loss: 2.0743e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 507us/step - loss: 1.7706e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 499us/step - loss: 1.3755e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 1.1734e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 1.0634e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 492us/step - loss: 9.7625e-05 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBF0626C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.1998 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 751us/step - loss: 0.9863 - accuracy: 0.4919\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.7173 - accuracy: 0.7661\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.4866 - accuracy: 0.9113\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.3005 - accuracy: 0.9516\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.1674 - accuracy: 0.9758\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9758\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0502 - accuracy: 0.9758\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0226 - accuracy: 0.9919\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 501us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 752us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 8.5496e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 6.7377e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 6.0114e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 5.0107e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 4.2510e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 3.8190e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 3.3341e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBE8051790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.0372 - accuracy: 0.9815\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.9359 - accuracy: 0.5645\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 756us/step - loss: 0.6239 - accuracy: 0.8145\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.3613 - accuracy: 0.9435\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.1763 - accuracy: 0.9758\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0646 - accuracy: 0.9919\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0265 - accuracy: 0.9919\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 749us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 7.2049e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 4.4096e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 3.3955e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 2.7793e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 2.3416e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 752us/step - loss: 2.0496e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 1.5766e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 1.4528e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 1.2252e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 500us/step - loss: 1.1714e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 750us/step - loss: 1.0555e-04 - accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001CBF049F550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 481us/step - loss: 0.1135 - accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "accuracy_features_size=[]\n",
    "features_list=[0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "features_size=[int(i*13) for i in sizes]\n",
    "for i in features_size:\n",
    "    sel_features=random.sample(features_list,i)\n",
    "    Xtrain=X_train[:,sel_features]\n",
    "    Xtest=X_test[:,sel_features]\n",
    "    model=tf.keras.models.Sequential([tf.keras.layers.Dense(13,activation=tf.nn.relu),\n",
    "                         tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(10,activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(3,activation=tf.nn.softmax)])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(lr=0.015),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(Xtrain,Y_train,epochs=20,batch_size=32)\n",
    "    accuracy_features_size.append(model.evaluate(Xtest,Y_test,batch_size=32))\n",
    "df4=pd.DataFrame(accuracy_features_size,columns=['loss','Accuracy']) #storing all the accuries in the Dataframe\n",
    "df4[\"feature set ratio\"]=[i for i in sizes]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>feature set ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.526648</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.711238</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487270</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.396684</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.233261</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.235491</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.199779</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.037150</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.113504</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  Accuracy  feature set ratio\n",
       "1  0.526648  0.685185                0.3\n",
       "0  0.711238  0.740741                0.2\n",
       "3  0.487270  0.907407                0.5\n",
       "2  0.396684  0.925926                0.4\n",
       "4  0.233261  0.962963                0.6\n",
       "5  0.235491  0.962963                0.7\n",
       "6  0.199779  0.981481                0.8\n",
       "7  0.037150  0.981481                0.9\n",
       "8  0.113504  0.981481                1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.sort_values(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAEWCAYAAACzATTWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6VklEQVR4nO3daZhU1bn28f/NJDI7oKIo4IiCggQQRzTGMSLE2Zg4JMZ41ETzHo0mJkYznGDMiUmOGqeDHDNo4kSc0ThWIxGaCAo4IYoiGkFEJhWR5/2wdkPR9lANXV3Vzf27rrqq9vzU7up6aq299lqKCMzMzKw8tCp1AGZmZraGE7OZmVkZcWI2MzMrI07MZmZmZcSJ2czMrIw4MZuZmZURJ2YzM7My4sRcpiS9IekjSUvzHls3wj6/1FgxtnQt9XxJmpH3mfpM0sd50z9ch/2NlfTzAtaTpNmSZq5b5GYbhjalDsDqNCIi/lHqIKpIahMRK0sdR75yjKncRUS/qteSngT+FBE3N8GhDwC2ANpIGhIRk5vgmIA/J9a8uMTczEjqKul/Jb0j6W1JP5fUOlu2g6THJb0vaYGkP0vqli37I7AdcF9WMvq+pAMlza22/9WlREmXS7pT0p8kLQZOr+f4O0p6StKH2fH/Wst76C0pJJ0laV62r//MW95K0iWSXsvey98kbVpt229KehN4PJv/LUkvSloiaaakQdn8rSXdJWm+pNclfTfvOJdn+741226GpMG1na9s/h2S3s3e49OS8pPcZpLuk7RY0uTs3FTkLe8r6VFJCyW9LOmEWs7PSZIqq837nqR7a1j39KwUuiR7f6fUtM9CSfpGdh4/kDReUq9sviRdLem97L0/L6m/pLOAU4DvZ+fpvjp2fxrwd+DB7HX+cfvlnZt/Kyu5S2ot6YfZZ2GJpCmSts37HLTJ28eTks7MOy8TspgXAperjv+PbJttJd2dfVbel3SNpI2ymHbPW28Lpdqs7utzrs1qFRF+lOEDeAP4Ug3zxwE3AB1JpY9JwLezZTsChwAbAd2Bp4Hf1rZP4EBgbm3HBS4HPgVGkX7EbVzP8W8DLs3WbQ/sV8t76w1Etn5HYHdgft5xLwD+CfTM3ssNwG3Vtr0123Zj4HjgbWAIoOw89MrimAJcBrQDtgdmA4flvb+PgSOB1sAvgX/W9TcAvgF0zuL6LTA1b9nt2aMDsBvwFlCRLeuYTZ9BqqkaBCwA+tVwfjoAS4Cd8uZNBk6qtl5HYDGwSzbdo6b91fM5exI4M3s9CpgF7JrF+CPgmWzZYdm57Jad412BHtmyscDP6zlOhyzWI4Fjs/feLlvWGXgH+M/sc9MZ2CtbdhHwArBLdtwBwGZ5n4M2tbyX04GVwHey97Ixdfx/ZH//acDV2Xld/fkFrgOuzDvO+cB9pf6O8KPlPkoegB+1/GFSUlgKLMoe44AtgU+AjfPWOxl4opZ9jAKeq7bPhibmp/OW1Xl8UrK8EehZz3ur+lLtmzfvV8D/Zq9fBA7OW9aD9AOhTd622+ctHw+cX8Nx9gLerDbvB8Atee/vH3nLdgM+qu181bD/blksXbMv9k/JkmS2/OesScwnArlq298A/KSWff8JuCx7vRMpUXeotk7H7LNxbP7fpIGfsydZk8weAr6Zt6wVsJz0I+eLwCvAMKBVtX2Mpf7E/DXSj682pMS4CPhK3mfouVq2exkYWcdnqK7E/GY9MY2qOi6wd1V8tXyO3qp630AlcMK6nG8//Cjk4ars8jYqIrplj1GkL8i2wDuSFklaRPpy3wJWV7HdrlTFvJj05b75esbwVt7rOo8PfJ9UqpmUVQt/owH7ngNUNW7rBdyTd4wXgc9IPwxq2nZb4LUa9t8L2LpqP9m+flhtP+/mvV4OtM+vHs2XVauOzqpVF5MSN6Rz3J2UdPLjqn7u9qoWyynAVjUdC/gLKWEBfBUYFxHL81eIiGWkhH826W/ygKS+teyvEL2A3+XFt5D099wmIh4HrgGuBf4t6UZJXRqw79OAv0XEyoj4BLibNdXZtf396ltWn/zzX9//x7bAnKjhOnREPAssA4Zn53dH4HOXFcwaixNz8/IWqcS6eV7C7hJrGvP8klSK2CMiupBKKcrbvvpQYstIVYxASjykBJMvf5s6jx8R70bEtyJia+DbwHWSdqzj/Wyb93o7YF7ecY7IO0a3iGgfEW/XEdcONez/LeD1avvpHBFH1hFTvurn66vASOBLpFJy72y+SKWtlaTq95re31vAU9Vi6RQR/1HLsR8BNpc0kJSg/1JjgBHjI+IQUq3CS8BNBb63mrxFuiyRH+PGEfFMdqzfR8QXgH7AzqRqZvj8eVqLpJ6kEvfXsuvz7wLHAUdK2pza/37UsWxZ9twhb171HznV46rr/+MtYLvafpQB/5et/3Xgzoj4uJb1zNabE3MzEhHvkL6w/1tSF6VGUjtIGp6t0pms+lvSNqz54qzyb9J11iqvkEqIX5bUlnRNcaN1Pb6k47MvYYAPSF+Cn9Xxln4sqYNSA6ozgKrGYtcDv8hreNRd0sg69nMzcKGkL2SNlHbMtp0ELJZ0saSNsxJvf0lD6thXvurnqzPph8n7pITwX1ULIuIzUinw8uw99QVOzdv2fmBnSV+X1DZ7DJG0a00HzkpudwJXAZsCj1ZfR9KWko6W1DGLayl1n+/6XA/8IPt7VDU0PD57PUTSXtnnZBnp2nzVsaqfp+q+Tvqs7QIMzB47A3NJPzruB7aSdEHW2KqzpL2ybW8GfiZpp+xvu4ekzSJiPqldwdeyv+s3qD25V6nr/2MS6Tr3aEkdJbWXtG/e8j8CXyEl51vrOY7ZenFibn5OJTVkmklKfneSSksAV5AaFX0IPEBKFPl+Cfwoq6q8MCI+BM4hffm9TfrCnUvd6jr+EOBZSUtJVX3nR8TrdezrKVJjo8eAX0fEI9n832XbPyJpCakh2F417wIi4g7gF6RS5RLS9fhNs2Q5gpQIXic1OLqZVNotxFrni/SFPId0rmZmceU7L9v3u6Qv8ttICZOIWAIcCpxEqhl4F7iSOn4IZe/nS8AdVVWskk6RNCNb3orUYGoeqdp5OOnviaT9s79DwSLiniym27Oq3unAEdniLqTS+AfZOXgf+HW27H+B3bLzNK6GXZ8GXJfVqKx+kH4InJadm0NIf6t3gVeBg7JtfwP8jfSDcHF2rI2zZd8iJdf3SaX4Z+p5i7X+f+R9VnYE3iT9H5yYt3wu8C/Sj81cPccxWy+KqLMWyqzRSepNSpRta7qm11JIuhLYKiJOq3dlK3uSxgDzIuJHpY7FWjZ3MGLWSLLq63ak23uGAN8EzixpUNYosh+TxwB7ljgU2wC4Ktus8XQmVY8uI1W//jepQw1rxiT9jFStf1U9l2bMGoWrss3MzMqIS8xmZmZlpEVdY958882jd+/epQ7DzKzZmDJlyoKIcL/fZaRFJebevXtTWVlZ/4pmZgaApDmljsHW5qpsMzOzMuLEbGZlae7cuYwcOZKddtqJHXbYgfPPP58VK1bUuc2iRYu47rrrVk/PmzeP4447rlHiufzyy/n1r3/9ufnz589nr732Ys899ySXa3jfI2PHjmXevHn1r9iMSeom6ZwmOM7Rki5Zx20PVxqOdVZt+8h6w7tP0jSl8QDOqG97SZsqDWn6ava8SX2xODGbWdmJCI455hhGjRrFq6++yiuvvMLSpUu59NJL69yuemLeeuutufPOO4sa62OPPUbfvn157rnn2H///Ru8/bok5pUrm6Zfnqz//MbQjaxXumKKiHsjYnRDt8ve57Wknu52A06WtFsNq54LzIyIAaTR+f5bUrt6tr8EeCwidiL1cljvDwcnZjMrO48//jjt27fnjDNSgaR169ZcffXVjBkzhuXLlzN27FhGjhzJ4Ycfzi677MIVV1wBwCWXXMJrr73GwIEDueiii3jjjTfo378/kBLgqFGjGDFiBH369OGaa67hN7/5DXvuuSfDhg1j4cKFANx0000MGTKEAQMGcOyxx7J8+fKagwSmTp3K97//fR588EEGDhzIRx99xCOPPMLee+/NoEGDOP7441m6NPWM+tOf/pQhQ4bQv39/zjrrLCKCO++8k8rKSk455ZTV2/fu3ZsFCxYAUFlZyYEHHgikEvtZZ53FoYceyqmnnsr8+fM59thjGTJkCEOGDGHChAmfi6+28wTwpz/9iaFDh0LqTvWGqiQsaamkn0p6Fthb0qmSns9KiX/M1uku6S5Jk7PHvtn8yyWNkfSkpNmSvpsdbjSwg6Spkq6S1EnSY5L+JemF/L7wJf1Y0ktZ6fK2rDtclPrlf1jSFEk51TCSmqTTJV2TvT5e0vQs7qdr/SMmQ4FZETE7IlaQxlWvqX/+ADpLEtCJ1BXuynq2H0kaBIXseVQ9sbSs8Zi/8IUvhJk1f7/73e/iggsu+Nz8gQMHxrRp0+KWW26JrbbaKhYsWBDLly+Pfv36xeTJk+P111+Pfv36rV4/f/qWW26JHXbYIRYvXhzvvfdedOnSJf7whz9ERMQFF1wQV199dURELFiwYPX2l156afz+97+PiIif/OQncdVVV30upltuuSXOPffciIiYP39+7L///rF06dKIiBg9enRcccUVERHx/vvvr97ma1/7Wtx7770RETF8+PCYPHny6mW9evWK+fPnR0TE5MmTY/jw4auPP2jQoFi+fHlERJx88smRy+UiImLOnDnRt2/fGmOr6TzNnDkzjjrqqFixYkWQxpe+Djg1Ur8WQTbeNKkP8pdJI8pB6oMeUj/u+2WvtwNezF5fTuqzfCPSkJrvk4aK7Q1Mj+y7mtTwuEv2enNSn/kCBgNTSf2hdyb1m35htt5jwE7Z672Ax6NaDiCNw31N9voF0pClAN2qr1ttu+OAm/Omv161n2rrdQaeIA14shT4cn3bA4uq7eODumKJiJbVKtvMmrk//xkuvZSYMwd17gyDB8Mpp6xeHBGkwgoccsghbLbZZgAcc8wxVFRUMGrUqDp3f9BBB9G5c2c6d+5M165dGTFiBAC77747zz//PADTp0/nRz/6EYsWLWLp0qUcdthhBYf/z3/+k5kzZ7LvvmlgqhUrVrD33nsD8MQTT/CrX/2K5cuXs3DhQvr167f6+IU6+uij2XjjNIbHP/7xD2bOnLl62eLFi1myZAmdO3dea5uazlObNm2YMmUKQ4YMgVT12hl4L9vkM+Cu7PUXScNcLgCIiIXZ/C+RStpVh+kiqerAD0Qac/sTSe+x9vjnVQT8l6QDgFXANtl6+wF/j4iPACTdlz13AvYB7sg7Zl0DwABMAMZK+hufH9Cnpniqq6n3rcNIPxy+SBrN7FFJuQZsXxAnZjMrD3/+M5x1FixfTj/griVL0jTAKaewePFi3nrrLXbYYQemTJlC3hc0wOema7LRRmu+y1u1arV6ulWrVquv255++umMGzeOAQMGMHbsWJ588smC30JEcMghh3DbbbetNf/jjz/mnHPOobKykm233ZbLL7+cjz+ueUjnNm3asGrVqtXb5evYsePq16tWrWLixImrE3VtajpPEcFpp53GL3/5SyTNjIjB+eFGGm0LUsKpKcG0AvauSqDVjvVJ3qzPqDnPnEIa+/0LEfGppDeA9tSc4KqOtygiBtay/HMi4uxs+NAvA1MlDYyI92tZfS5rj5/ekzXjw+c7Axgdqeg7S9LrQN96tv+3pB4R8Y6kHqz5AVQrJ2YzKw+XXgrZ9dyDSS1kbl2+nKPPvZRfv3gSDz74n+y88+mMHt2BadPg8ccfZYstFtKmzcaMGTOOESPG8NZbnZk7dwmXXZZ2uWgRvPceXHYZTJsG8+ax1rLRo6FDh7WX/fvfS7j11h60b/8pt932Zzp33obLLoOnnoJ27WDx4rXDzt922bJhPPjguZx33iw23XRHPv10OYsXz6Vjxy1Ytgyuu25zIpYyZsyd7LrrcaxaBfPmdeb3v19CVd9Iq1b15oILprDjjkfwyCN38e671Hj8rbY6lBEjrmGffS6iUyc49NCpDBw48HOn9dFHH2XhwoVsvPHGjBs3jjFjxtChQwdGjhzJ9773PSC1HAY6R0T1e5ofA+6RdHVEvC9p06zU/AhpmNOrsu0HRsTUOv66S0il8ipdgfeypHwQ0CubXwHcIOmXpPz0ZeCmiFgs6XVJx0fEHdk13j0iYlptB5S0Q0Q8SxqKdgQpcdaWmCcDO0nqQxrW9STgqzWs9ybp45mTtCVpjPHZwKI6tr+XNPTp6Oy5/v7z66vrbk4PX2M2a37eey/ippsiPkMRsPrxJsRREDtCwPYB5wV8HFIE3BJwfMCRATsHXB5SZMtODugXcGHA6wH98rY5N2+9XgHzP7cMrgvoHTA8O+Zp2fyfBFy1evs1+6m+38cCBgfsnj3+ns2/NGCHgIMDTg/4STb/zuw9DAhYHvB0wE4B+wX8Z8DwGo8P8wNOCNg9WrfeNb797W9/7tzecsstcfzxx8eRRx4ZO++8c1x++eWrl91+++0xYMCAAJYDU4Bhka6BLo21r4meRhrEYxowNtZcF/4r8DxpbPLrY8015gvztp0O9M5e/yWbvirbfiLp+vbNwIt5611Ouq79CPBn4FvZ/D7Aw1kcM4HL8uOMz19jvpt0nXk6aYx3VV+/2rZHAq8ArwGX5s0/Gzg7e711FlfVfr9WwPabkX7gvJo9b1pXHBHRsgaxGDx4cLjnL7Py9847cM89cOedqSS4ahXMbdObbVbW0AlVr17wxhtrzRo7diyVlZVcc801TRNwM1XIeZI0Jdauyi4pSZ0iYqmkDsDTwFkR8a9Sx9WUfLuUmTWJOXPg6qthv/1gm23g3HPh3Xfhhz+E556Drcf+ItUr5+vQAX7xi9IEbKVyo6SpwL+Auza0pAwtbNhHl5jNysurr8Jdd6VH1b/mgAFw7LHpsVv1LhyyVtm8+SZst11Kynmtsq3xlVuJ2ZyYzawRRcDMmWuScXYHEkOHpkR8zDGw446ljdHW5sRcftwq28zWS0Sqiq5Kxi+/DBLsu2+quj7mmFT4NbPCODGbWYOtWgWTJqXGW3ffDa+/Dq1bw4EHwvnnw6hR0KNHqaM0a56cmM2sIJ99BhUVqVR8993w9tvQti186UvpsvDIkbD55qWO0qz5c2I2s1p9+ik88URKxuPGpc462reHww9PnXMcdRR061bqKM1aFidmM1vLxx/Do4+mZHzvvfDBB9CxI3z5y3DccXDEEdCpU6mjNGu5nJjNjGXL4OGHUzK+/35YsgS6doWjj06tqQ89FOrpktnMGokTs1mRffRRui233ETAv/6VkvFDD6U4N9sMTjghlYy/+MXUN7OZNS0nZrMiev31lOCq9ShZVrbaCs44I5WMDzgA2vhbwayk/C9oViSvvpqS8vLlcPPNn+9tshz06gXDhkErd85rVjacmM2K4KWXUlL+9FN4/PHUDaWZWSGcmM0a2fTpcPDBqferJ5+Efv1KHZGZNSeuwDJrRFOnpt6v2rRJwxk6KZtZQzkxmzWSyspUfd2hQ0rKu+xS6ojMrDkqamKWdLiklyXNknRJDcs3kXSPpOclTZLUP2/ZG5JekDRVkoeMsrI2cWKqvu7WDZ5+2iMomdm6K1piltQauBY4AtgNOFlS9dFXfwhMjYg9gFOB31VbflBEDPSQZFbOnn46dcCx5ZappNy7d6kjMrPmrJgl5qHArIiYHRErgNuBkdXW2Q14DCAiXgJ6S9qyiDGZNarHH09dVPbsmRp6bbttqSMys+aumIl5G+CtvOm52bx804BjACQNBXoBPbNlATwiaYqks2o7iKSzJFVKqpw/f36jBW9Wn/HjU//R22+fkvLWW5c6IjNrCYqZmFXDvKg2PRrYRNJU4DvAc8DKbNm+ETGIVBV+rqQDajpIRNwYEYMjYnD37t0bJ3Kzetx/f+pHum/fNPrSlq7nMbNGUsz7mOcC+RV7PYF5+StExGLgDABJAl7PHkTEvOz5PUn3kKrGny5ivGYFueceOPHE1GnI+PGw6aaljsjMWpJilpgnAztJ6iOpHXAScG/+CpK6ZcsAzgSejojFkjpK6pyt0xE4FJhexFjNCvLXv8Lxx8PgwfCPfzgpm1njK1qJOSJWSjoPGA+0BsZExAxJZ2fLrwd2BW6V9BkwE/hmtvmWwD2pEE0b4C8R8XCxYjUrxJ/+BKedBvvuCw88AJ07lzoiM2uJFFH9sm/zNXjw4Kis9C3P1vjGjIEzz4SDDoJ774WOHUsdkVnjkDTFt6SWF/f8ZVaP66+Hb34z3at8//1OymZWXE7MZnX4/e/hP/4DjjoKxo2DjTcudURm1tI5MZvV4qqr4Pzz4StfgbvugvbtSx2RmW0InJjNavCLX8D3v59ui/rrX6Fdu/q3MTNrDE7MZnki4Cc/gR/9CL7+9dQSu23bUkdlZhuSYnYwYtasRMAPfgBXXgnf+AbceCO0bl3qqMxsQ+PEbEZKyv/v/8Fvf5sae11zDbRyfZKZlYC/emyDt2oVnHdeSsrnnw/XXuukbGal468f26CtWgXf/jZcdx1cdBFcfTWopuFXzMyaiBOzNdiECfDww7BiRakjWT+ffZauJd98c2rsdeWVTspmVnq+xmwNsmpVGu5w4ULo2hVGjIBjj4XDDmtenW+sXAmnngq33QY//Sn8+MeljsjMLHFitgaZMSMl5fPOg6VL4e9/T7cUdewIX/5yStJHHgmdOpU60tqtWAFf/WrqNOTKK9P9ymZm5cKJ2RqkoiI9f+97sP328Omn8MQTKcmNGwd/+1vqIeuww1KSHjECunUrZcRr++STNGzjffel68kXXFDqiMzM1uZrzNYguRz06AF9+qTptm3T4A433ADz5sGTT8K3vgWVlamqeIst4Igj4H//FxYsKGnofPQRjBqVkvK11zopm1l5cmK2gkWkxLz//jU3kmrdGoYPTwM/vPkmTJyYbj966aU0ZOJWW8HBB6cW0O+807SxL1+ero2PHw833QTnnNO0xzczK5QTsxXszTdh7lzYb7/6123VCoYNSwNBzJ4NU6bAxRfD22/DuefCNtuk/Vx9ddpvMS1dmq57P/44jB2bfiSYmZUrJ2YrWC6Xnvffv2HbSTBoUBoY4sUXYfp0uPxyWLIk9bbVqxcMHZoaYs2a1bgxf/hhut5dUZEaqZ16auPu38yssTkxW8FyOejSBXbffd33IUG/fnDZZTBtGrzyCowenarJL7kEdtoJBgxItzDNnLl+8X7wARxyCEyalEaIOvnk9dufmVlTUESUOoZGM3jw4KisrCx1GC1Wv36w3Xbw0EPF2f+cOXD33amF9zPPpGTdt29q3X3ssTBwYOEdgLz/fkrKM2bAHXek68tm9nmSpkTE4FLHYWu4xGwFef/9VIJtaDV2Q/TqlW7DqqhI16KvvRa23hp++ctUFb7jjqnbzH/+M3V0Upv33oODDkrx/v3vTspm1rw4MVtBJkxIz8VMzPl69Egtpx97DN59N7Wk3nln+N3vYO+9U8n9/PPh6adT15pV3nkHDjwwXat+4AE4/PCmidfMrLE4MVtBcjlo1w6GDGn6Y3fvnlpSP/RQKg3feisMHpzunR4+PJWqzz4b7rknTb/5Zlr34IObPlYzs/Xla8xWkGHDoE2bNT1/lYOlS+HBB9M16QcegGXLoHPnlJT33bfU0Zk1D77GXH7cJafVa/nydB/yhReWOpK1deoEJ5yQHh99lKq9t98edtut1JGZma27olZlSzpc0suSZkm6pIblm0i6R9LzkiZJ6l/ottZ0nn02jcZUSMcipbLxxnDUUU7KZtb8FS0xS2oNXAscAewGnCyp+tfmD4GpEbEHcCrwuwZsa00kl0u3Ke2zT6kjMTNr+YpZYh4KzIqI2RGxArgdGFltnd2AxwAi4iWgt6QtC9zWmkhFBfTvD5tsUupIzMxavmIm5m2At/Km52bz8k0DjgGQNBToBfQscFtrAitXpsEomuo2KTOzDV0xE3NNfTRVbwI+GthE0lTgO8BzwMoCt00Hkc6SVCmpcv78+esRrtVk6tTU+tmJ2cysaRSzVfZcYNu86Z7AvPwVImIxcAaAJAGvZ48O9W2bt48bgRsh3S7VSLFbpur2qHJu+GVm1pIUs8Q8GdhJUh9J7YCTgHvzV5DULVsGcCbwdJas693WmkYuB717Q8+epY7EzGzDULQSc0SslHQeMB5oDYyJiBmSzs6WXw/sCtwq6TNgJvDNurYtVqxWs4hUYj7ssFJHYma24ShqByMR8SDwYLV51+e9ngjsVOi21rRefTV1gelqbDOzpuO+sq1WuVx6dsMvM7Om48RstaqogM02S2Mim5lZ03BitlrlcqkaWzXdvGZmZkXhxGw1eucdeO01V2ObmTU1J2arUdX9y07MZmZNq97ELGnTpgjEyksuBx06wJ57ljoSM7MNSyEl5mcl3SHpyKx3LtsA5HIwbBi0bVvqSMzMNiyFJOadSV1efh2YJem/JO1c3LCslD78EJ5/3vcvm5mVQr2JOZJHI+JkUreZpwGTJD0lae+iR2hNbuJEWLXK15fNzEqh3p6/JG0GfI1UYv43aRSoe4GBwB1AnyLGZyVQUQGtW6eqbDMza1qFdMk5EfgjMCoi5ubNr5R0fS3bWDOWy6VGX506lToSM7MNTyGJeZeIqHE4xYi4spHjsRL75BN49lk455xSR2JmtmEqpPHXI5K6VU1I2kTS+OKFZKU0ZUpKzr6+bGZWGoUk5u4RsahqIiI+ALYoWkRWUlUDV+y7b2njMDPbUBWSmD+TtF3VhKReQI1V29b85XKwyy6whX96mZmVRCHXmC8FKiQ9lU0fAJxVvJCsVFatggkT4LjjSh2JmdmGq97EHBEPSxoEDAMEfC8iFhQ9MmtyM2bAokXuWMTMrJQKKTEDfAa8B7QHdpNERDxdvLCsFKquL7vhl5lZ6RTSwciZwPlAT2AqqeQ8EfhiUSOzJldRAT16QB93GWNmVjKFNP46HxgCzImIg4A9gflFjcqaXEQqMe+/P3ioEjOz0ikkMX8cER8DSNooIl4CdiluWNbU3nwT5s51NbaZWakVco15btbByDjgUUkfAPOKGZQ1varry274ZWZWWoW0yv5K9vJySU8AXYGHixqVNblcDrp0gd13L3UkZmYbtjoTs6RWwPMR0R8gIp6qa31rvioqUm9frVuXOhIzsw1bndeYI2IVMC2/5y9red5/H2bOdDW2mVk5KOQacw9ghqRJwLKqmRFxdH0bSjoc+B3QGrg5IkZXW94V+BOwXRbLryPilmzZG8AS0j3UKyNicCFvyBquoiI9u+GXmVnpFZKYr1iXHUtqDVwLHALMBSZLujciZuatdi4wMyJGSOoOvCzpzxGxIlt+kHsZK76KCmjXDoYMKXUkZmZWSOOvdb2uPBSYFRGzASTdDowE8hNzAJ0lCegELARWruPxbB3lcikpt29f6kjMzKze+5glLZG0OHt8LOkzSYsL2Pc2wFt503OzefmuAXYl3X71AnB+dl0bUtJ+RNIUSbUOmiHpLEmVkirnz3e/Jw21bFkag9nV2GZm5aGQEnPn/GlJo0il4frU1H9U9eEiDyN18/lFYAfSfdK5iFgM7BsR8yRtkc1/qab+uSPiRuBGgMGDB3s4ygaaNAlWrnTDLzOzclFIz19riYhxFNZP9lxg27zpnny+Y5IzgLsjmQW8DvTNjjMve34PuIfCfgxYA+VyqQvOffctdSRmZgaFDWJxTN5kK2Awny/51mQysJOkPsDbwEnAV6ut8yZwMJCTtCWpq8/ZkjoCrSJiSfb6UOCnBRzTGiiXS52KdOtW6kjMzAwKa5U9Iu/1SuANUiOuOkXESknnAeNJt0uNiYgZks7Oll8P/AwYK+kFUtX3xRGxQNL2wD2pTRhtgL9EhHsba2QrV8LEiXDaaaWOxMzMqhRyjfmMdd15RDwIPFht3vV5r+eRSsPVt5sNDFjX41phpk5Njb/c8MvMrHwU0ir7/7JBLKqmN5E0pqhRWZOo6ljEDb/MzMpHIY2/9oiIRVUTEfEBaUxma+ZyOejdG3r2LHUkZmZWpZDE3ErSJlUTkjalsGvTVsYiUmJ2NbaZWXkpJMH+N/CMpDtJrbFPAH5R1Kis6F59FebPd2I2Mys3hTT+ulVSJeneZQHHVOvv2pqhXC49+/qymVl5KeQ+5mHAjIi4JpvuLGmviHi26NFZ0eRysNlm0LdvqSMxM7N8hVxj/gOwNG96WTbPmrGKilRaVk0dp5qZWckUkpgVEat7+soGmXDjr2bsnXfgtdd8fdnMrBwVkphnS/qupLbZ43xgdrEDs+Kpur7sxGxmVn4KScxnA/uQ+rueC+wFfKuYQVlxVVRAhw6wp+9GNzMrO4W0yn6PNAAFAJI2Bo4C7ihiXFZEuRwMGwZt25Y6EjMzq66gYR8ltZZ0hKRbSUMznljcsKxYPvwQnn/e1dhmZuWqzhKzpANIQzV+GZgE7AtsHxHLmyA2K4KJE2HVKt+/bGZWrmpNzJLmksZL/gNwUTY28utOys1bLgetW6eqbDMzKz91VWXfBWxDqrYeIakjqUtOa8YqKmDQIOjUqdSRmJlZTWpNzBFxPtAb+A1wEPAK0F3SCZL8td4MffIJPPusq7HNzMpZnY2/Ink8Ir5FStJfBUYBbxQ9Mmt0lZUpObvhl5lZ+Sq4B6+I+BS4D7gvu2XKmpmKivTsErOZWfkq6Hap6iLio8YOxIovl4NddoHu3UsdiZmZ1WadErM1P6tWwYQJrsY2Myt39SZmSccXMs/K24wZsGiRq7HNzMpdISXmHxQ4z8qYB64wM2se6upg5AjgSGAbSb/PW9QFWFnswKxxVVTA1ltDnz6ljsTMzOpSV6vseUAlcDQwJW/+EuB7xQzKGldEKjHvtx9IpY7GzMzqUlcHI9Mi4v+AHSPi/7LX9wKzIuKDQnYu6XBJL0uaJemSGpZ3lXSfpGmSZkg6o9BtrXBz5sDcua7GNjNrDgq5xvyopC6SNgWmAbdI+k19G0lqDVwLHAHsBpwsabdqq50LzIyIAcCBwH9LalfgtlagqvuXnZjNzMpfIYm5a0QsBo4BbomILwBfKmC7oaTS9eyIWAHcDoystk4AnSUJ6AQsJF2/LmRbK1AuB126QP/+pY7EzMzqU0hibiOpB3ACcH8D9r0N8Fbe9NxsXr5rgF1J17NfAM6PiFUFbguApLMkVUqqnD9/fgPC23DkcrDvvmlUKTMzK2+FJOafAuOB1yJisqTtgVcL2K6mZkbVR6c6DJgKbA0MBK6R1KXAbdPMiBsjYnBEDO7uLq0+Z8ECePFFV2ObmTUX9faVHRF3AHfkTc8Gji1g33OBbfOme5JKxvnOAEZHRACzJL0O9C1wWyvAhAnp2R2LmJk1D4X0/LWzpMckTc+m95D0owL2PRnYSVIfSe2Ak0ituvO9CRyc7XdLYBdgdoHbWgFyOWjXDoYMKXUkZmZWiEKqsm8i9fT1KUBEPE9KlHWKiJXAeaRq8BeBv0XEDElnSzo7W+1nwD6SXgAeAy6OiAW1bduwt2aQWmQPGQLt25c6EjMzK0Qhwz52iIhJWrtnioJ6/oqIB4EHq827Pu/1PODQQre1hlm2DKZMgQsvLHUkZmZWqFpLzJK2y14ukLQDWeMrSccB7zRBbLaeJk2ClSvd8MvMrDmpq8Q8DhhEqlK+Aegr6W3gdeBrxQ/N1lcul7rg3GefUkdiZmaFqisxCyAiXgO+JKkj0CoiljRJZLbecjnYfXfo1q3UkZiZWaHqSszVR5UCoOpac0R8t1hB2fpbuRImToTTTy91JGZm1hB1JeaPWHtUKWtGpk5Njb98/7KZWfNSV2J+PxtRypqhXC49u+GXmVnzUtd9zCuaLAprdBUV0KcPbFNjD+NmZlau6hqPeVhTBmKNJyKVmF2NbWbW/BTS85c1M6+8AvPnuxrbzKw5cmJugSoq0rNLzGZmzY8TcwuUy8Hmm0PfvqWOxMzMGsqJuQWqqEilZdU0qrWZmZU1J+YW5p134LXXXI1tZtZcOTG3ML5/2cyseXNibmEqKqBDB9hzz1JHYmZm68KJuYXJ5WDYMGjbttSRmJnZunBibkE+/BCmTXM1tplZc+bE3IJMnJh6/XJiNjNrvpyYW5BcDlq3hr32KnUkZma2rpyYW5BcDgYNgk6dSh2JmZmtKyfmFuKTT2DSJN+/bGbW3DkxtxCVlSk5+/qymVnz5sTcQnjgCjOzlsGJuYXI5WCXXaB791JHYmZm68OJuQVYtQomTHA1tplZS1DUxCzpcEkvS5ol6ZIall8kaWr2mC7pM0mbZsvekPRCtqyymHE2dzNmwKJFTsxmZi1Bm2LtWFJr4FrgEGAuMFnSvRExs2qdiLgKuCpbfwTwvYhYmLebgyJiQbFibCmqBq7w9WUzs+avmCXmocCsiJgdESuA24GRdax/MnBbEeNpsXI52Hpr6NOn1JGYmdn6KmZi3gZ4K296bjbvcyR1AA4H7sqbHcAjkqZIOqu2g0g6S1KlpMr58+c3QtjNS0RKzPvvD1KpozEzs/VVzMRcU5qIWtYdAUyoVo29b0QMAo4AzpV0QE0bRsSNETE4IgZ33wCbJM+ZA2+/7WpsM7OWopiJeS6wbd50T2BeLeueRLVq7IiYlz2/B9xDqhq3aqquL7vhl5lZy1DMxDwZ2ElSH0ntSMn33uorSeoKDAf+njevo6TOVa+BQ4HpRYy12aqogK5doX//UkdiZmaNoWitsiNipaTzgPFAa2BMRMyQdHa2/Pps1a8Aj0TEsrzNtwTuUbpo2gb4S0Q8XKxYly2Djh2LtffiyuVgn33SqFJmZtb8FS0xA0TEg8CD1eZdX216LDC22rzZwIBixlblgw/S9dljj4UrrmheDagWLIAXX4Svf73UkZiZWWPZ4Hv+6tIFhg2Dn/0MfvCD1Mq5uZgwIT274ZeZWctR1BJzc9C6Ndx0E2y0EVx5ZRqh6Te/aR4l51wO2rWDIUNKHYmZmTWWDT4xA7RqBddem5Lcb38LK1bA//xPml/OKipg6FBo377UkZiZWWNxYs5IcPXVqeT8q1+l5HzDDeWbnJctgylT4MILSx2JmZk1JifmPBKMHp1Kzj//eUrOY8aUZ4vnZ5+FlSt9/7KZWUvjxFyNlBqCtWsHl10Gn34Kt94KbcrsTFVUpFj32afUkZiZWWMqs3RTPn7841StffHFqeT8l7+kZF0ucjnYfXfo1q3UkZiZWWMq0yuo5eH730/Xne+6C447LrXYLgcrV8LEia7GNjNriZyY63HBBanF9n33wahR8NFHpY4Ipk5Njb+cmM3MWh4n5gKcc06613n8eBgxApYvL208VQNXuGMRM7OWx4m5QGeeCWPHwhNPwJFHwtKlpYulogL69IFtahzd2szMmjMn5gY49VT4859TYjzsMPjww6aPISKVmF1aNjNrmZyYG+ikk+Cvf4VJk+CQQ9IgGE3plVdg/nxfXzYza6mcmNfBscfC3XfDtGlw8MHw/vtNd+yKivTsxGxm1jI5Ma+jESPg73+HmTPhoIPgvfea5ri5HGy+OeyyS9Mcz8zMmpYT83o4/HB44AGYNQsOPBDeeaf4x6y6vtwcRr8yM7OGc2JeTwcfDA89BG++CcOHw9y5xTvWvHkwe7arsc3MWjIn5kYwfDg88gj8+9/p9Zw5xTlO1fVlt8g2M2u5nJgbyT77wKOPwsKFcMABqWTb2HI56NAB9tyz8fdtZmblwYm5EQ0dCo89ljofOeCAdGtTY6qogL33hrZtG3e/ZmZWPpyYG9mgQfDkk2lEquHDU6vtxvDhh+n2LFdjm5m1bE7MRbD77ik5Q2qt/cIL67/PZ55JvX654ZeZWcvmxFwku+0GTz2VxnA+6CB47rn1219FBbRuDXvt1TjxmZlZeXJiLqKdd07JuWNH+OIXUzee6yqXS9XknTo1XnxmZlZ+ipqYJR0u6WVJsyRdUsPyiyRNzR7TJX0madNCtm0udtgBnn4aNt0UvvSlVCXdUJ98kpK6q7HNzFq+oiVmSa2Ba4EjgN2AkyXtlr9ORFwVEQMjYiDwA+CpiFhYyLbNSa9eqeTcowccemh63RCVlSk5u+GXmVnLV8wS81BgVkTMjogVwO3AyDrWPxm4bR23LXs9e6YGYb16wRFHpNuqCpXLpWcnZjOzlq+YiXkb4K286bnZvM+R1AE4HLhrHbY9S1KlpMr58+evd9DF1KMHPPEE7LgjHHUUPPxwYdtVVEDfvtC9e3HjMzOz0itmYq5pmIWoZd0RwISIWNjQbSPixogYHBGDuzeDzLXFFik577orjBwJ991X9/qrVsGECS4tm5ltKIqZmOcC2+ZN9wTm1bLuSaypxm7ots3OZpulquyBA+GYY+Cuu2pfd/p0WLTIDb/MzDYUxUzMk4GdJPWR1I6UfO+tvpKkrsBw4O8N3bY522ST1Lf20KFw4olw++01r1c1cIUTs5nZhqFNsXYcESslnQeMB1oDYyJihqSzs+XXZ6t+BXgkIpbVt22xYi2VLl1g/Ph0vfmUU1I3nqeeuvY6uRxsvTX07l2SEM3MrIkporbLvs3P4MGDo7KystRhNNjy5el682OPwU03wTe/meZHwLbbpuvLtZWozczWh6QpETG41HHYGu75qwx06AD33guHHQZnngnXXZfmz5kDb7/thl9mZhuSolVlW8NsvDGMGwcnnADnnpuqtTfbLC3z9WUzsw2HE3MZ2WgjuOMO+OpX4XvfS9eVu3aF/v1LHZmZmTUVV2WXmXbt0vXkk0+GN96AffZJo0qZmdmGwSXmMtSmDfzxjzBgABxwQKmjMTOzpuTEXKZat4aLLy51FGZm1tRclW1mZlZGnJjNzMzKiBOzmZlZGXFiNjMzKyNOzGZmZmXEidnMzKyMODGbmZmVESdmMzOzMtKihn2UNB+Ys46bbw4saMRwGovjahjH1TCOq2FaYly9IqJ7YwZj66dFJeb1IamyHMckdVwN47gaxnE1jOOypuCqbDMzszLixGxmZlZGnJjXuLHUAdTCcTWM42oYx9UwjsuKzteYzczMyohLzGZmZmXEidnMzKyMbFCJWdLhkl6WNEvSJTUsP0XS89njGUkDyiSukVlMUyVVStqvKeIqJLa89YZI+kzSceUQl6QDJX2YnbOpki4rh7jyYpsqaYakp8ohLkkX5Z2r6dnfctMyiKurpPskTcvO1xnFjqnAuDaRdE/2fzlJUv8miGmMpPckTa9luST9Pov5eUmDih2TFUlEbBAPoDXwGrA90A6YBuxWbZ19gE2y10cAz5ZJXJ1Y0x5gD+Clcjlnees9DjwIHFcOcQEHAveX4WesGzAT2C6b3qIc4qq2/gjg8XKIC/ghcGX2ujuwEGhXBnFdBfwke90XeKwJztcBwCBgei3LjwQeAgQMa4rvLz+K89iQSsxDgVkRMTsiVgC3AyPzV4iIZyLig2zyn0DPMolraWT/eUBHoKla7NUbW+Y7wF3Ae2UWV1MrJK6vAndHxJsAEdEU56yh5+tk4LYyiSuAzpJE+oG6EFhZBnHtBjwGEBEvAb0lbVnMoCLiadL7r81I4NZI/gl0k9SjmDFZcWxIiXkb4K286bnZvNp8k/Trs9gKikvSVyS9BDwAfKMJ4iooNknbAF8Brm+imAqKK7N3VgX6kKR+ZRLXzsAmkp6UNEXSqWUSFwCSOgCHk35olUNc1wC7AvOAF4DzI2JVGcQ1DTgGQNJQoBdN80O+Lg39jrMytSElZtUwr8aSp6SDSIn54qJGlB2uhnmfiysi7omIvsAo4GfFDipTSGy/BS6OiM+KH85qhcT1L1IfwAOA/wHGFTsoCourDfAF4MvAYcCPJe1cBnFVGQFMiIi6SmaNpZC4DgOmAlsDA4FrJHUpblgFxTWa9ANrKqnG6DmKX5KvT0P+zlbG2pQ6gCY0F9g2b7on6Vf4WiTtAdwMHBER75dLXFUi4mlJO0jaPCKK3Zl+IbENBm5PNY1sDhwpaWVEjCtlXBGxOO/1g5Kua4JzVsj5mgssiIhlwDJJTwMDgFdKHFeVk2iaamwoLK4zgNHZpZxZkl4nXdOdVMq4ss/XGZAaXQGvZ49SatB3iZWxUl/kbqoH6UfIbKAPaxp09Ku2znbALGCfMotrR9Y0/hoEvF01XerYqq0/lqZp/FXIOdsq75wNBd4s9jkrMK5dSdcm2wAdgOlA/1LHla3XlXQNs2Ox/4YNOF9/AC7PXm+ZffY3L4O4upE1QgO+Rbq22xTnrDe1N/76Mms3/prUFDH50fiPDabEHBErJZ0HjCe1uhwTETMknZ0tvx64DNgMuC4rAa6MIo/YUmBcxwKnSvoU+Ag4MbL/xDKIrckVGNdxwH9IWkk6ZycV+5wVEldEvCjpYeB5YBVwc0TUePtLU8aVrfoV4JFIpfmiKzCunwFjJb1ASjgXR5FrigqMa1fgVkmfkVrZf7OYMQFIuo10t8HmkuYCPwHa5sX0IKll9ixgOVmJ3pofd8lpZmZWRjakxl9mZmZlz4nZzMysjDgxm5mZlREnZjMzszLixGxmZlZGnJjNAEkXZN1Rlur4V2WjJ11Vbf5Gkv6Rjfp04jrsd5Sk3RovUjMrtg3mPmZreSS1iYjG6gbxAuBPpPs/S+HbQPeI+KTa/D2BthExcB33Owq4n3SvbUEa+byaWQO5xGwlI6m3pJck/V82fuydVaVWSV+Q9FQ20MP4qlFyssEf/isbx/h8pXGgn8kGq5gkqbOk1lkJdHK2329n2x6YbX9ndtw/Z2PYfpfUF/MTkp7I1v2D0tjXMyRdkRfzkdm2FdnYt/dn8zsqjZc7WdJzkj43elN2rKuUxjt+oaoELOle0qhhz+aXiiVtQfqxMDArMe9Qx3n5VnbsaZLuktRB0j7A0cBVeds/KWlwts3mkt7IXp8u6Q5J9wGP1PZ+JPXLzvPU7Nzu1GgfCDNLSt31mB8b7oPUvWAA+2bTY4ALSb0ZPUMqQQKcSOp9CeBJ4LrsdTtS14lDsukupFqgs4AfZfM2AipJ3SseCHxI6kO4FTAR2C9b7w3yunoENs2eW2fH3ANoTxq9p0+27DayMZ+B/wK+lr3uRur7umO193ss8Gi2zy1J3YT2yJYtreUcHZh3jLrOy2Z52/wc+E72eix53aRm72Vw9npz4I3s9emkvpY3rev9kAYEOSXv/G9c6s+RH360tIersq3U3oqICdnrPwHfBR4G+gOPKnWN2hp4J2+bv2bPuwDvRMRkWDNwhaRDgT0kHZet1xXYCVhB6j94brbeVNKPg4oa4jpB0lmkRN+DNP5uK2B2RFQNVnAb6UcAwKHA0ZIuzKbbk/pefzFvn/sBt0UaievfWal/CHBv3adotV2o/bz0l/RzUhLtROpOsqEejTWjStX2fiYCl0rqSRpX+tV1OI6Z1cGJ2Uqtep+wQeoTeUZE7F3LNlV9OauG7avmfyci1kpOkg4E8q/hfkYN/wOS+pBK7kMi4gNJY0mJqaZh9fKPeWxEvFzPOuujrvMyFhgVEdMknU4qaddkJWsuYbWvtiy/j+za3s+Lkp4lDZgwXtKZEfF44W/BzOrja8xWattJqko0J5NKry8D3avmS2orqV8N274EbC1pSLZeZ0ltSKXF/5DUNpu/s6SO9cSxBOicve5CSlIfStoSOCLveNtL6p1N57eSHg98R1lRVtKeNRzjaeDE7Bp4d+AAGjZ8YV3npTPwTvaeT6nlfUGqsv9C9vo4alfj+5G0PanW4Pekkv4eDYjfzArgxGyl9iJwmqTngU2BP0TEClLSuFLSNGAqsE/1DbP1TgT+J1vvUVIp8GZSK+R/SZoO3ED9tUM3Ag9JeiIippEGvp9Buu49ITveR8A5wMOSKoB/k65ZQxoFqS3wfHbMn9VwjHtIo0pNAx4Hvh8R79YTV/X3W9t5+THwbHYOXsrb7HbgoqwB1w7Ar0k/Wp4hXWOuTW3v50RgenYZoC9wa6Hxm1lhPLqUlUxW8rw/IvqXOpZCSeoUEUuzkuS1wKsRcXWp4zKzlsMlZrOG+VZWWpxBalR2Q2nDMbOWxiVmMzOzMuISs5mZWRlxYjYzMysjTsxmZmZlxInZzMysjDgxm5mZlZH/D/bTMsi9ljsvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx4=df4[df4[\"Accuracy\"]==df4.max()[\"Accuracy\"]]\n",
    "_ = plt.plot(df4[\"feature set ratio\"],df4['Accuracy'],'b')\n",
    "_ = plt.plot(idx4.iloc[0,2],idx4.iloc[0,1],'ro')\n",
    "_ = plt.annotate(f'Optimal feature percentage is  {idx4.iloc[0,2]:.3f}',(idx4.iloc[0,2],idx4.iloc[0,1]))\n",
    "_ = plt.xlabel('percentage of features ')\n",
    "_ = plt.ylabel(' Test Accuracy')\n",
    "_ = plt.title('Features percentage v.s. Test Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
